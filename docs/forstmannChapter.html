<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC</title>
  <meta name="description" content="Particle Based Sampler for MCMC" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Particle Based Sampler for MCMC" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC" />
  
  <meta name="twitter:description" content="Particle Based Sampler for MCMC" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pmwg-sampler-and-signal-detection-theory.html"/>
<link rel="next" href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PMwG Samplers Package</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to particle based sampler for MCMC</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#assumed-knowledge"><i class="fa fa-check"></i><b>1.1</b> Assumed knowledge</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#why-would-you-use-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.2</b> Why would you use Particle Metropolis within Gibbs sampling?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#the-assumed-hierarchical-structure"><i class="fa fa-check"></i><b>1.3</b> The assumed hierarchical structure</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#what-particle-metropolis-within-gibbs-sampling-provides"><i class="fa fa-check"></i><b>1.4</b> What Particle Metropolis within Gibbs sampling provides</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#what-is-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.5</b> What is Particle Metropolis within Gibbs sampling?</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#generating-proposals-in-pmwg-sampling-using-particle-metropolis"><i class="fa fa-check"></i><b>1.6</b> Generating proposals in PMwG sampling using Particle Metropolis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html"><i class="fa fa-check"></i><b>2</b> PMwG sampler and Signal Detection Theory</a><ul>
<li class="chapter" data-level="2.0.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline"><i class="fa fa-check"></i><b>2.0.1</b> Signal Detection Theory analysis of lexical decision task</a></li>
<li class="chapter" data-level="2.0.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#SDTLLFun"><i class="fa fa-check"></i><b>2.0.2</b> The log-likelihood function</a></li>
<li class="chapter" data-level="2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#testing-the-sdt-log-likelihood-function"><i class="fa fa-check"></i><b>2.1</b> Testing the SDT log-likelihood function</a></li>
<li class="chapter" data-level="2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtWag"><i class="fa fa-check"></i><b>2.2</b> SDT log-likelihood function for Wagenmakers experiment</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#description-of-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2.1</b> Description of Wagenmakers experiment</a></li>
<li class="chapter" data-level="2.2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#computation-time-of-the-log-likelihood-function"><i class="fa fa-check"></i><b>2.2.2</b> Computation time of the log-likelihood function</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtPMwG"><i class="fa fa-check"></i><b>2.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="2.3.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>2.3.1</b> Model start points</a></li>
<li class="chapter" data-level="2.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#run-sdtsampler"><i class="fa fa-check"></i><b>2.3.2</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#check-the-sampling-process"><i class="fa fa-check"></i><b>2.4</b> Check the sampling process</a></li>
<li class="chapter" data-level="2.5" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#simulating-posterior-data"><i class="fa fa-check"></i><b>2.5</b> Simulating posterior data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="forstmannChapter.html"><a href="forstmannChapter.html"><i class="fa fa-check"></i><b>3</b> PMwG sampler and sequential sampling models</a><ul>
<li class="chapter" data-level="3.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#the-speed-accuracy-tradeoff-in-perceptual-decisions"><i class="fa fa-check"></i><b>3.1</b> The speed-accuracy tradeoff in perceptual decisions</a></li>
<li class="chapter" data-level="3.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#LBAParameters"><i class="fa fa-check"></i><b>3.2</b> Linear Ballistic Accumulator Parameters</a></li>
<li class="chapter" data-level="3.3" data-path="forstmannChapter.html"><a href="forstmannChapter.html#theLLFunc"><i class="fa fa-check"></i><b>3.3</b> The log-likelihood function</a><ul>
<li class="chapter" data-level="3.3.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#what-is-a-log-likelihood-function"><i class="fa fa-check"></i><b>3.3.1</b> What is a log-likelihood function?</a></li>
<li class="chapter" data-level="3.3.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#writing-the-log-likelihood-function-for-the-forstmann-data-set"><i class="fa fa-check"></i><b>3.3.2</b> Writing the log-likelihood function for the Forstmann data set</a></li>
<li class="chapter" data-level="3.3.3" data-path="forstmannChapter.html"><a href="forstmannChapter.html#fstLBALL"><i class="fa fa-check"></i><b>3.3.3</b> Fast LBA Log-likelihood Function</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="forstmannChapter.html"><a href="forstmannChapter.html#pmwg-framework"><i class="fa fa-check"></i><b>3.4</b> PMwG Framework</a><ul>
<li class="chapter" data-level="3.4.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#lbaStartPts"><i class="fa fa-check"></i><b>3.4.1</b> Model start points</a></li>
<li class="chapter" data-level="3.4.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#run-sampler"><i class="fa fa-check"></i><b>3.4.2</b> Running the sampler</a></li>
<li class="chapter" data-level="3.4.3" data-path="forstmannChapter.html"><a href="forstmannChapter.html#estSet"><i class="fa fa-check"></i><b>3.4.3</b> Determining estimation settings for the PMwG sampler</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="forstmannChapter.html"><a href="forstmannChapter.html#genppdatafunc"><i class="fa fa-check"></i><b>3.5</b> Simulating Posterior Predictive Data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#assessing-descriptive-adequacy-goodness-of-fit"><i class="fa fa-check"></i><b>3.5.1</b> Assessing Descriptive Adequacy (goodness of fit)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="forstmannChapter.html"><a href="forstmannChapter.html#evaluating-different-models---single-threshold-lba"><i class="fa fa-check"></i><b>3.6</b> Evaluating different models - single threshold LBA</a><ul>
<li class="chapter" data-level="3.6.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#pmwg-framework-for-a-single-threshold-model"><i class="fa fa-check"></i><b>3.6.1</b> PMwG framework for a single threshold model</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="forstmannChapter.html"><a href="forstmannChapter.html#checking-descriptive-adequacy-of-1b-model."><i class="fa fa-check"></i><b>3.7</b> Checking Descriptive Adequacy of 1b model.</a></li>
<li class="chapter" data-level="3.8" data-path="forstmannChapter.html"><a href="forstmannChapter.html#forstMC"><i class="fa fa-check"></i><b>3.8</b> Model Comparison</a><ul>
<li class="chapter" data-level="3.8.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#assessing-descriptive-adequacy-graphically"><i class="fa fa-check"></i><b>3.8.1</b> Assessing Descriptive Adequacy Graphically</a></li>
<li class="chapter" data-level="3.8.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#forstDIC"><i class="fa fa-check"></i><b>3.8.2</b> Model comparison via DIC</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="forstmannChapter.html"><a href="forstmannChapter.html#LBAllcheck"><i class="fa fa-check"></i><b>3.9</b> Checking the LBA log-likelihood function</a><ul>
<li class="chapter" data-level="3.9.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#test-one-do-changes-in-parameter-values-cause-changes-in-the-returned-log-likelihood"><i class="fa fa-check"></i><b>3.9.1</b> Test one: Do changes in parameter values cause changes in the returned log-likelihood?</a></li>
<li class="chapter" data-level="3.9.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#testing-whether-data-generating-parameter-values-have-the-highest-likelihood"><i class="fa fa-check"></i><b>3.9.2</b> Testing whether data generating parameter values have the highest likelihood</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><i class="fa fa-check"></i><b>4</b> PMwG sampler with the Linear Ballistic Accumulator and a complex experiment design</a><ul>
<li class="chapter" data-level="4.1" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#the-lba-log-likelihood-function-for-the-wagenmakers-data-set"><i class="fa fa-check"></i><b>4.1</b> The LBA log-likelihood function for the Wagenmakers data set</a><ul>
<li class="chapter" data-level="4.1.1" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#what-is-a-log-likelihood-function-1"><i class="fa fa-check"></i><b>4.1.1</b> What is a log-likelihood function?</a></li>
<li class="chapter" data-level="4.1.2" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#writing-the-lba-log-likelihood-for-the-wagenmakers-data-set"><i class="fa fa-check"></i><b>4.1.2</b> Writing the LBA log-likelihood for the Wagenmakers data set</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#wagFastll"><i class="fa fa-check"></i><b>4.2</b> Fast LBA Log-likelihood function</a></li>
<li class="chapter" data-level="4.3" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#pmwg-framework-1"><i class="fa fa-check"></i><b>4.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="4.3.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#run-sampler"><i class="fa fa-check"></i><b>4.3.1</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#genppdataWag"><i class="fa fa-check"></i><b>4.4</b> Simulating Posterior Predictive Data</a><ul>
<li class="chapter" data-level="4.4.1" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#assessing-descriptive-adequacy-goodness-of-fit-1"><i class="fa fa-check"></i><b>4.4.1</b> Assessing Descriptive Adequacy (goodness of fit)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#model-comparison-via-dic"><i class="fa fa-check"></i><b>4.5</b> Model Comparison via DIC</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><i class="fa fa-check"></i><b>5</b> Estimating the Marginal Likelihood via Importance Sampling (IS<sup>2</sup>)</a><ul>
<li class="chapter" data-level="5.1" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#using-is2-with-the-forstmann-dataset"><i class="fa fa-check"></i><b>5.1</b> Using IS2 with the Forstmann dataset</a><ul>
<li class="chapter" data-level="5.1.1" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#load-packages-and-samples"><i class="fa fa-check"></i><b>5.1.1</b> Load packages and samples</a></li>
<li class="chapter" data-level="5.1.2" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#set-up-variables"><i class="fa fa-check"></i><b>5.1.2</b> Set up variables</a></li>
<li class="chapter" data-level="5.1.3" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#store-the-samples"><i class="fa fa-check"></i><b>5.1.3</b> Store the samples</a></li>
<li class="chapter" data-level="5.1.4" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#estimate-the-normal-mix"><i class="fa fa-check"></i><b>5.1.4</b> Estimate the normal mix</a></li>
<li class="chapter" data-level="5.1.5" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#generate-proposal-parameters-from-importance-samples"><i class="fa fa-check"></i><b>5.1.5</b> Generate proposal parameters from importance samples</a></li>
<li class="chapter" data-level="5.1.6" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#write-a-group-distribution-function"><i class="fa fa-check"></i><b>5.1.6</b> Write a group distribution function</a></li>
<li class="chapter" data-level="5.1.7" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#write-a-prior-distribution-function"><i class="fa fa-check"></i><b>5.1.7</b> Write a prior distribution function</a></li>
<li class="chapter" data-level="5.1.8" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#write-a-get_logp-function"><i class="fa fa-check"></i><b>5.1.8</b> Write a get_logp function</a></li>
<li class="chapter" data-level="5.1.9" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#compute-the-lw"><i class="fa fa-check"></i><b>5.1.9</b> Compute the LW</a></li>
<li class="chapter" data-level="5.1.10" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#make-it-work"><i class="fa fa-check"></i><b>5.1.10</b> Make it work</a></li>
<li class="chapter" data-level="5.1.11" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#bootstrapping-for-se"><i class="fa fa-check"></i><b>5.1.11</b> Bootstrapping for SE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="troubleshoot.html"><a href="troubleshoot.html"><i class="fa fa-check"></i><b>6</b> Troubleshooting PMwG errors</a><ul>
<li class="chapter" data-level="6.1" data-path="troubleshoot.html"><a href="troubleshoot.html#writing-your-log-likelihood-function-tips-errors-and-check-list"><i class="fa fa-check"></i><b>6.1</b> Writing your log-likelihood function: Tips, errors and check list</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>7</b> Appendix</a><ul>
<li class="chapter" data-level="7.1" data-path="appendix.html"><a href="appendix.html#wagSDTscript"><i class="fa fa-check"></i><b>7.1</b> Wagenmakers SDT script</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://newcastlecl.org/" target="blank">Published by Newcastle Cognition Lab</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Particle Based Samplers for MCMC</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="forstmannChapter" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> PMwG sampler and sequential sampling models</h1>
<p>In this chapter we’ll demonstrate how to use the PMwG sampler with a sequential sampling model; the Linear Ballistic Accumulator (LBA). Please ensure the <code>PMwG</code> and <code>rtdists</code> packages are loaded.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pmwg)
<span class="kw">library</span>(rtdists)
<span class="kw">require</span>(tidyverse)</code></pre></div>
<div id="the-speed-accuracy-tradeoff-in-perceptual-decisions" class="section level2">
<h2><span class="header-section-number">3.1</span> The speed-accuracy tradeoff in perceptual decisions</h2>
<p>We demonstrate the application of the LBA with the PMwG sampler in a study of perceptual decision making. <span class="citation">Forstmann et al. (<a href="#ref-forstmann2008striatum">2008</a>)</span> looked at neural correlates of decision making under time pressure, with an aim to identify areas of the brain associated with speed-accuracy tradeoff. Imaging (fMRI) and behavioural data was collected; however, we will analyse behavioural data from the decision-making task only. In terms of modelling the data, Forstmann expected to find differences in thresholds for each of the three speed-emphasis conditions. We have included the Forstmann et als data in the <code>PMwG</code> package as a data frame named <code>forstmann</code>. The sampler requires a data frame with a <b><code>subject</code></b> column. The subject column data type can be a factor or numeric.</p>
<p>Table <a href="forstmannChapter.html#tab:forsthead10">3.1</a> shows the first ten trials from the Forstmann dataset. Participants <code>(n = 19)</code> were asked to indicate whether a cloud of dots in a random-dot kinematogram (RDK) moved to the left or the right of the screen. The IV was a within-subject, speed-accuracy manipulation where, before each trial began, pariticipants were instructed to make their choice <i>accurately</i> <code>(condition = 1)</code>, with <i>urgency</i><code>(condition = 3)</code>or were presented with a <i>neutral</i> message <code>(condition = 2)</code>. Stimuli moved either <i>left</i> <code>(stim = 1)</code> or <i>right</i> <code>(stim = 2)</code> and responses were <i>left</i> <code>(resp = 1)</code> or <i>right</i> <code>(resp = 2)</code>. Response times <code>(rt)</code> were recorded in seconds. For more information about the design of the experiment please see <a href="https://www.pnas.org/content/105/45/17538.short">the original paper</a>.</p>
<table>
<caption><span id="tab:forsthead10">Table 3.1: </span>First 10 trials in Forstmann dataset. The <code>forstmann</code> dataset is a data frame</caption>
<thead>
<tr class="header">
<th align="center">subject</th>
<th align="center">condition</th>
<th align="center">stim</th>
<th align="center">resp</th>
<th align="center">rt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4319</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.5015</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3104</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4809</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3415</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3465</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3572</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4042</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3866</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.3683</td>
</tr>
</tbody>
</table>
</div>
<div id="LBAParameters" class="section level2">
<h2><span class="header-section-number">3.2</span> Linear Ballistic Accumulator Parameters</h2>
<p>There are preliminary steps we need to complete before running the sampler. Let’s begin by defining the Linear Ballistic Accumulator (LBA) <span class="citation">(Brown and Heathcote <a href="#ref-brown2008simplest">2008</a>)</span> model parameters.</p>
<ul>
<li><code>b</code> threshold parameter (the evidence required to trigger a response)</li>
<li><code>v</code> is the mean drift rate or average speed of evidence accumulation</li>
<li><code>A</code> is the range of start points for accumulators</li>
<li><code>t0</code> is non-decision time</li>
<li><code>sv</code> is the standard deviation of the across-trial distribution of drift rates</li>
</ul>
</div>
<div id="theLLFunc" class="section level2">
<h2><span class="header-section-number">3.3</span> The log-likelihood function</h2>
<div id="what-is-a-log-likelihood-function" class="section level3">
<h3><span class="header-section-number">3.3.1</span> What is a log-likelihood function?</h3>
<p>If you’re unsure what a log-likehood function is and/or does, see our explanation <a href="pmwg-sampler-and-signal-detection-theory.html#WTFisaLLf">here</a>.</p>
</div>
<div id="writing-the-log-likelihood-function-for-the-forstmann-data-set" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Writing the log-likelihood function for the Forstmann data set</h3>
<p>Just as we did with the <a href="pmwg-sampler-and-signal-detection-theory.html#SDTLLFun">SDT chapter</a>, we’ll write a slow and a fast log-likelihood function. The trialwise (slow) log-likelihood function is approximately five times slower than the fast log-likelihood function because the <code>dLBA</code> function is called line-by-line (trialwise), where as the <code>dLBA</code> function is called once for all the data in the fast log-likelihood function. When writing a new log-likelihood function, we suggest starting with a slow, line-by-line function for easier debugging. See section <a href="forstmannChapter.html#LBAllcheck">3.9</a> for a detailed debugging process.</p>
<p>The LBA log-likelihood function takes three arguments:</p>
<ul>
<li><code>x</code> is a named parameter vector (e.g. <code>pars</code>)</li>
<li><code>data</code> is your dataset (e.g.<code>forstmann</code>). Your dataset must include a <code>&quot;subject&quot;</code> column</li>
<li><code>sample = FALSE</code> calculates a density function or <code>TRUE</code> generates a posterior predictive sample that matches the shape of data.</li>
</ul>
<p>The log-likelihood function shown below includes functions from the <code>rtdists</code> package for generating data and estimating density. If you’d like to run through this example, it is best to copy the <code>tw_lba_ll</code> function from the code block below rather than copying from the separate code chunks where curly braces have been removed.</p>
<p><b>Note</b>: The trialwise log-likelihood is very slow and inneficient because <code>rLBA</code> and <code>dLBA</code> will be called on each line of the data. This will result in very slow sampling times and is a consequence of the <code>rtdists</code> package, not an issue with the PMwG sampling speed. If you have experience writing log-likelihoods, we recommend writing a faster version than our trialwise function, or use the fast log-likelihood we have written in section <a href="forstmannChapter.html#fstLBALL">3.3.3</a>. If you are new to modelling, we recommend trying the trialwise (slow) log-likelihood function as it is easier to follow, troubleshoot and is less likely to result in errors.</p>
<p>Let’s begin by loading the <code>rtdists</code> package…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rtdists)</code></pre></div>
<p>and now our complete trialwise (slow) log-likelihood function.</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">tw_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  
  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
    vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
    ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    
    <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
      vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
      } <span class="cf">else</span> {
      vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
      }
    
    <span class="cf">if</span> (sample) {
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    } <span class="cf">else</span> {
      out[i] &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt[i],
                     <span class="dt">response =</span> data<span class="op">$</span>resp[i],
                     <span class="dt">A =</span> A,
                     <span class="dt">b =</span> b,
                     <span class="dt">mean_v =</span> vs,
                     <span class="dt">sd_v =</span> s,
                     <span class="dt">t0 =</span> t0,
                     <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                     <span class="dt">silent =</span> <span class="ot">TRUE</span>
      )
      }
  }
  
<span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }
}</code></pre></td></tr></table></div>
<p>The first line in the <code>tw_lba_ll</code> function (Line 2 below) takes the exponent of the parameter values. We do this as the LBA requires positive parameter values that are on the real line. Line 3 and 4 then checks RTs are faster than the non-decision time parameter <code>t0</code>, and returns a low value if <code>t0</code> is larger than RT, indicating that the given value of <code>t0</code> is unlikely.</p>
<div class="sourceCode" startFrom="2"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>2
3
4
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)</code></pre></td></tr></table></div>
<p>Now we create a vector with values sampled from the posterior distribution OR estimating the density. If <code>sample = TRUE</code>, we remove all responses <code>(resp)</code> and rts. This means when we return <code>data</code>, we are returning the posterior predictive data which matches with the associated <code>subject</code> and <code>condition</code> and then generate them from the random function of the model.</p>
<p>If <code>sample = FALSE</code> (the <code>else</code> statement from line 11) we create an <code>out</code> vector, with a length equal to the number of rows in the dataset, and store the likelihood value for each subject and condition.</p>
<div class="sourceCode" startFrom="7"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>7
8
9
10
11
12
13
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }</code></pre></td></tr></table></div>
<p>Next, we loop over rows in the dataset. In this <code>for</code> loop, we find the values <code>(x)</code> of each parameter in our model for each row, so that any conditional parameters (for example <code>b</code> in our model) are correctly assigned. For example, we want to calculate the density for a model that has three threshold parameters (one for each condition; <code>1  = accuracy</code>, <code>2 = neutral</code>, or <code>3 = speed</code>). In the loop, we paste <code>b.</code> to the condition in row <code>[i]</code> and add <code>A</code> (the start point - we do this to ensure the threshold is greater than the starting point).</p>
<p>On line 22 we set the order of our drift rate parameters. Recall that <code>stim = 1</code> is a stimulus moving to the left. <code>dLBA</code> requires the drift accumulators to be matched i.e. when <code>data$stim[i] == 1</code>, the drift rate for the correct accumulator <code>(vc)</code> is in position one, so we order the drift rates; <code>vs = c(vc, ve)</code>. The <code>else</code> statement addresses right moving stimuli <code>data$stim[i] == 2</code>, the incorrect accumulator <code>(ve)</code> is the first accumulator, so the drift rate parameter order is <code>vs = c(ve, vc)</code>. This ensures that the correct <code>(vc)</code> and error <code>(ve)</code> drift rates match with the corresponding accumulators for given stimuli.</p>
<div class="sourceCode" startFrom="15"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
    vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
    ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
      vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
    } <span class="cf">else</span> {
      vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
    }</code></pre></td></tr></table></div>
<p>The following section calls the relevant <code>rtdists</code> function depending on whether we are sampling from the posterior predictive distribution <code>(rLBA)</code> or estimating the density <code>(dLBA)</code>. We then input the parameters from above (using the names set above) into the relevant function. When generating data from the posterior predictive distribution (Line 30-37), <code>rLBA</code> is called for each line of the data, storing the generated <code>rt</code> and <code>response</code> given the posterior parameter estimates in the <code>tmp</code> vector (which we then reassign to the empty <code>data$rt</code> and <code>data$resp</code> columns). We set <code>n = 1</code>, since we are calling <code>rLBA</code> on 1 row of the data. When estimating the density (Line 42 to 50), dLBA is called for each line of the data, storing the probability of the <code>rt</code> and <code>response</code> under the proposed parameters <code>(x)</code> in the <code>out</code> vector.</p>
<div class="sourceCode" startFrom="29"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample) {
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    } <span class="cf">else</span> {
      out[i] &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt[i],
                     <span class="dt">response =</span> data<span class="op">$</span>resp[i],
                     <span class="dt">A =</span> A,
                     <span class="dt">b =</span> b,
                     <span class="dt">mean_v =</span> vs,
                     <span class="dt">sd_v =</span> s,
                     <span class="dt">t0 =</span> t0,
                     <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                     <span class="dt">silent =</span> <span class="ot">TRUE</span>
      )
      }</code></pre></td></tr></table></div>
<p>This final section tells the function what to return; <code>data</code> - when sampling posterior predictive data (Line 56) - or the sum of the likelihoods - when estimating density (Line 57 - 61). On line 58 we take all implausible likelihood values, assign them to the <code>bad</code> object and then (line 59) set them to an extremely unlikely value, to prevent numerical errors. The final two lines within the <code>else</code> statement take the log of all likelihood values, sums them, assigns the model’s log-likelihood value to the <code>out</code> variable and returns that value.</p>
<div class="sourceCode" startFrom="55"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>55
56
57
58
59
60
61
62
</pre></td><td class="sourceCode"><pre><code class="sourceCode r"><span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }</code></pre></td></tr></table></div>
</div>
<div id="fstLBALL" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Fast LBA Log-likelihood Function</h3>
<p>As the data is large, and the <code>dLBA</code> function takes some time to run, the log-likelihood code above is computationally inefficient. There are several ways to improve the log-likelihood’s performance; in our example below, we reduce the number of calls to <code>dLBA</code> to one call. We do this by passing a list of <code>dLBA</code> parameter values for the length of the data.</p>
<p><b>Note:</b> When generating posterior predictive data, the <code>rLBA</code> function is still executed for each row of data; however, it is only executed several times, so computational efficiency is uncompromised.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fast_lba_ll3b &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  
  <span class="cf">if</span> (sample) {
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  
  <span class="cf">if</span> (sample) {
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
      A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
      b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
      vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
      ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
      t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
      s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
      
      <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
        vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
      } <span class="cf">else</span> {
        vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
      }
      
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    }
  } <span class="cf">else</span> {
    all_b &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    vlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;v.1&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data)), 
                 <span class="st">&quot;v.2&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data)))
    stim &lt;-<span class="st"> </span><span class="kw">levels</span>(data<span class="op">$</span>stim)
    con &lt;-<span class="st"> </span><span class="kw">levels</span>(data<span class="op">$</span>condition)
    
    <span class="cf">for</span> (c <span class="cf">in</span> con) {
      <span class="cf">for</span> (s <span class="cf">in</span> stim) {
        use &lt;-<span class="st"> </span>data<span class="op">$</span>condition <span class="op">==</span><span class="st"> </span>c <span class="op">&amp;</span><span class="st"> </span>data<span class="op">$</span>stim <span class="op">==</span><span class="st"> </span>s
        <span class="cf">if</span> (<span class="kw">any</span>(use)) {
          bs =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, c)] <span class="op">+</span><span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
          all_b[use] =<span class="st"> </span>bs
          vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
          ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
          <span class="cf">if</span> (s <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
            vlist<span class="op">$</span>v.<span class="dv">1</span>[use] =<span class="st"> </span>vc
            vlist<span class="op">$</span>v.<span class="dv">2</span>[use] =<span class="st"> </span>ve
          } <span class="cf">else</span> {
            vlist<span class="op">$</span>v.<span class="dv">1</span>[use] =<span class="st"> </span>ve
            vlist<span class="op">$</span>v.<span class="dv">2</span>[use] =<span class="st"> </span>vc
          }
        }
      }
    }
    
    out &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt,
                <span class="dt">response =</span> data<span class="op">$</span>resp,
                <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                <span class="dt">b =</span>  all_b,
                <span class="dt">mean_v =</span> vlist,
                <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                <span class="dt">silent =</span> <span class="ot">TRUE</span>
    )
    }
  
  <span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }
}</code></pre></div>
<p>You should improve your log-likelihood’s performance as you see fit. When you’re confident that your log-likelihood code functions correctly, we suggest saving it as a separate script so it can be sourced and loaded when running the sampler. If you’re learning how to write log-likelihood functions, take a look at our <a href="troubleshoot.html#troubleshoot">troubleshooting section</a> for tips. In our experience, a very large proportion of problems with sampling and inference are caused by inadequate checking and care in the likelihood function.</p>
</div>
</div>
<div id="pmwg-framework" class="section level2">
<h2><span class="header-section-number">3.4</span> PMwG Framework</h2>
<p>Now that we have a log-likelihood function, we can set up the <code>PMwG</code> sampler. Running the sampler follows the same procedure outlined in the <a href="pmwg-sampler-and-signal-detection-theory.html#sdtPMwG">SDT chapter</a>; we need to set up a vector of model parameter names, create a <code>priors</code> object, source our LBA log-likelihood script and then create our <code>sampler</code> object.</p>
<p>Let’s begin by creating a vector of model parameter names, which we’ll use in our log-likelihood function. You can name this object as you wish; however, in our example, we name it <code>pars</code>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> For the <code>forstmann</code> dataset, we use three threshold parameters (one <code>b</code> for each condition) because we assume that the condition has an effect on level of caution, we include two drift rate parameters: <code>ve</code> for the incorrect accumulator and <code>vc</code> for the correct accumulator, a start point parameter <code>A</code> and a non-decision time <code>t0</code> parameter.</p>
<p>We’ve made a decision to set the <code>sv</code> to 1 to satisfy the scaling properties of the model. As such, we haven’t included the <code>sv</code> parameter in the <code>pars</code> vector - it is found in the LBA’s log-likelihood function (see above).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;b.1&quot;</span>, <span class="st">&quot;b.2&quot;</span>, <span class="st">&quot;b.3&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;ve&quot;</span>, <span class="st">&quot;vc&quot;</span>, <span class="st">&quot;t0&quot;</span>)</code></pre></div>
<p>For the mean of the distribution for random effects (theta_mu), we assume a multivariate normal prior. The user can specify the mean and variance of this prior distribution using the object <code>priors</code>, which has elements <code>theta_mu_mean</code> and <code>theta_mu_var</code>. A typical setting for LBA models is to set <code>theta_mu_mean</code> to be a zero vector and to set <code>theta_mu_var</code> to be a multiple of the identity matrix, e.g. with 9 on the diagonal (representing a standard deviation of 3 for the subject-level means in the prior).</p>
<p>We create our <code>priors</code> object; a list that contains two components:</p>
<ul>
<li><code>theta_mu_mean</code> a vector containing the prior for model parameter means</li>
<li><code>theta_mu_var</code> the prior covariance matrix for model parameters.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">priors &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">theta_mu_mean =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(pars)),
  <span class="dt">theta_mu_var =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(pars)))
)</code></pre></div>
<p>Now source and load your log-likelihood script <i>before</i> you create the sampler object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="dt">file =</span> <span class="st">&quot;dataObjects/fast_lba_ll3b.R&quot;</span>)</code></pre></div>
<p>Next we specify the PMwG <code>sampler</code> object. The <code>pmwgs</code> function takes a set of arguments (listed below) and returns a list containing the required components for performing the particle metropolis within Gibbs steps.</p>
<ul>
<li><code>data =</code> your data - a data frame (e.g.<code>forstmann</code>) with a column for participants called <b><code>subject</code></b></li>
<li><code>pars =</code> the model parameters to be used (e.g.<code>pars</code>)</li>
<li><code>prior =</code> the priors to be used (e.g.<code>priors</code>)</li>
<li><code>ll_func =</code> name of log-likelihood function to be used (e.g.<code>fast_lba_ll3b</code>)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">pmwgs</span>(<span class="dt">data =</span> data,
                 <span class="dt">pars =</span> pars,
                 <span class="dt">prior =</span> priors,
                 <span class="dt">ll_func =</span> fast_lba_ll3b
                 )</code></pre></div>
<div id="lbaStartPts" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Model start points</h3>
<p>There is also an option to set model start points. We have specified sensible start points for the <code>forstmann</code> dataset under the LBA model. If you choose not to specify start points, the sampler will randomly sample points from the prior distribution.</p>
<p>The <code>start_points</code> object contains two vectors:</p>
<ul>
<li><code>mu</code> a vector of start points for the mu of each model parameter</li>
<li><code>sig2</code> vector containing the start points of the covariance matrix of covariance between model parameters.</li>
</ul>
<p><b>Note:</b> <i>Start points must be on the real line. Our log-likelihood function immediately takes the exponent of the start points and only returns positive values, so we use the log of sensible start points here.</i></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">start_points &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">mu =</span> <span class="kw">log</span>(<span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">1.2</span>, <span class="fl">1.2</span>,
                                <span class="fl">1.4</span>, <span class="fl">1.3</span>, <span class="fl">3.5</span>, 
                                <span class="fl">0.13</span>)
                              ),
                     <span class="dt">sig2 =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(.<span class="dv">01</span>, <span class="kw">length</span>(pars)))
                     )</code></pre></div>
</div>
<div id="run-sampler" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Running the sampler</h3>
<p>Setup is now complete and we can run the sampler. First, we use the <code>init</code> function to generate initial start points for the random effects and store them in the <code>sampler</code> object. Here we specify start points by providing values for the <code>start_mu</code> and <code>start_sig</code> arguments. <b>Note</b>: The <code>init</code> stage can take some time to run because it uses a large number of particles</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">init</span>(sampler, 
                <span class="dt">start_mu =</span> start_points<span class="op">$</span>mu,
                <span class="dt">start_sig =</span> start_points<span class="op">$</span>sig2
                )</code></pre></div>
<p><br> To run the sampler, we use the <code>run_stage</code> function. To execute the <code>run_stage</code> function, you <b>must</b> provide values for two arguments:</p>
<ul>
<li><code>pmwgs =</code> the <code>sampler</code> object including parameters that were created by the <code>init</code> function above.</li>
<li><code>stage =</code> the sampling stage (In order; <code>&quot;burn&quot;</code>, <code>&quot;adapt&quot;</code> or <code>&quot;sample&quot;</code>).</li>
</ul>
<p>The following arguments listed below are optional:</p>
<ul>
<li><code>iter =</code> is the number of iterations for the sampling stage. For burn-in, it is important to have enough iterations that the chains converge on the posterior distribution. Default = 1000.</li>
<li><code>particles =</code> is the number of proposals (particles) generated for each random effect, on each iteration. Default = 1000, but set smaller or larger in order to target a reasonable acceptance rate (i.e. 10-60%).</li>
<li><code>display_progress =</code> display a progress bar during sampling</li>
<li><code>epsilon =</code> is a value greater than 0 which scales the variance of the proposal distribution. Smaller values (i.e. narrower proposal distributions) can lead to higher acceptance rates, but slower coverage of the posterior. Smaller values are especially useful when the number of random effects is large (e.g. &gt;10). The default is adaptively chosen based on the number of parameters.</li>
<li><code>n_cores =</code> the number of cores on a machine you wish to use to run the sampler. This allows sampling to be run across cores (parallelising for subjects). Default = 1. <b> Note:</b> Setting <code>n_cores</code> greater than 1 is only permitted on Linux and Mac OS X machines.</li>
</ul>
<p><br> The first sampling stage is burn-in <code>&quot;burn&quot;</code>. The burn-in stage allows time for the sampler to move from the (arbitrary) start points that were provided by the user to the mode of the posterior distribution. We take the <code>sampler</code> object created in the <code>init</code> function above, set the stage argument to <code>&quot;burn&quot;</code> and assign the outcome to an object called <code>burned</code>. <b>Note</b>: You should visually check the chains for convergence/stationarity after burn-in.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">burned &lt;-<span class="st"> </span><span class="kw">run_stage</span>(sampler, 
                    <span class="dt">stage =</span> <span class="st">&quot;burn&quot;</span>,
                    <span class="dt">iter =</span> <span class="dv">1000</span>,
                    <span class="dt">particles =</span> <span class="dv">100</span>,
                    <span class="dt">epsilon =</span> .<span class="dv">5</span>
                    )</code></pre></div>
<p>Next is the adaptation stage <code>&quot;adapt&quot;</code>. The adaptation stage draws samples using a simple, but relatively inefficient proposal distribution (the same proposal distribution as the <code>&quot;burn&quot;</code>stage). Enough samples are drawn to allow the algorithm to estimate a much more sophisticated and efficient proposal distribution, using conditional normal distributions. We take the <code>burned</code> object created in the previous stage and set iterations <code>iter =</code> to a high number (e.g. <code>10000</code>), as it should exit before reaching this point. If it doesn’t, there is likely an issue with acceptance rates, the likelihood function or limited data to operate on (i.e. few trials in some conditions). Here, we have saved the outcome of the adaptation stage to an object called <code>adapted</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adapted &lt;-<span class="st"> </span><span class="kw">run_stage</span>(burned, 
                     <span class="dt">stage =</span> <span class="st">&quot;adapt&quot;</span>, 
                     <span class="dt">iter =</span> <span class="dv">10000</span>, 
                     <span class="dt">particles =</span> <span class="dv">100</span>,
                     <span class="dt">epsilon =</span> .<span class="dv">5</span>
                     )</code></pre></div>
<p>The final stage is the sampling stage <code>&quot;sample&quot;</code>. The sampling stage uses the sophisticated and adaptive conditional normal proposal distributions. This allows for very efficient sampling, using far fewer particles. Samples from this stage are taken from the ‘posterior distribution’ and stored in the <code>sampled</code> object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampled &lt;-<span class="st"> </span><span class="kw">run_stage</span>(adapted, 
                     <span class="dt">stage =</span> <span class="st">&quot;sample&quot;</span>,
                     <span class="dt">iter =</span> <span class="dv">10000</span>, 
                     <span class="dt">particles =</span> <span class="dv">100</span>,
                     <span class="dt">epsilon =</span> .<span class="dv">5</span>
                     )</code></pre></div>
<p>The <code>sampled</code> object includes all samples from the <code>&quot;sample&quot;</code> stage above and the following elements:</p>
<ul>
<li><code>data</code> : the data (data frame) you included in your analysis</li>
<li><code>par_names</code>: parameter names</li>
<li><code>n_pars</code>: number of parameters</li>
<li><code>n_subjects</code>: number of subjects</li>
<li><code>subjects</code>: subject IDs (1:n)</li>
<li><code>prior</code>: list of the prior used</li>
<li><code>ll_func</code>: the likelihood function specified</li>
<li><code>samples</code>:</li>
<li><code>alpha</code>: three dimensional array of random effects draws (dim = parameters x subjects x samples)</li>
<li><code>theta_mu</code>: two dimensional array of parameter draws (dim = parameters x samples)</li>
<li><code>theta_sig</code>: three dimensional array of covariance matrix draws (dim = covariance x samples)</li>
<li><code>stage</code>: specifies the stage the sample is from (length = samples)</li>
<li><code>subj_ll</code>: likelihood value for each subject for each iteration (dim = subject x samples)</li>
<li><code>a_half</code>: the parameter used in calculating the inverse Wishart (dim = parameters x samples)</li>
<li><code>idx</code>: total number of samples</li>
<li><code>last_theta_sig_inv</code>: the inverse of the last sample for theta_sig (the variance-covariance matrix).</li>
</ul>
<p>You should save your sampled object at this point.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">save</span>(sampled, <span class="dt">file =</span> <span class="st">&quot;forst3bSamp.RData&quot;</span>)</code></pre></div>
</div>
<div id="estSet" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Determining estimation settings for the PMwG sampler</h3>
<p>Deciding on values for iterations and particles (and epsilon) is entirely model and data dependent. As model complexity increases, so to does the number of particles required. Increasing the number of particles gives the PMwG sampler a greater chance of finding a new particle on each iteration. For epsilon, as the number of parameters increases, the epsilon value decreases because smaller epsilon values restrict the sampling range/space. As a result, reaching the posterior space is slower, however, it means that we generate more particles closer to the current particle, which increases the amount of new particles accepted (i.e. acceptance rate). For the iterations, this also links in with number of particles and the value of epsilon. The main aim of the initial stages is to reach the posterior space and generate a conditional distribution from which we draw particles for each subject. If a model is complex, epsilon is small and there are few new particles on each iteration, we may need more iterations to ensure we get to this space OR we may need more particles to increase the amount of new particles on each iteration - meaning it is quicker to reach the posterior space. Note that increasing the particles and iterations will increase the time taken to run (with increased particles taking longer as this is evaluated for each subject). Ultimately, we should aim for between 10% and 80% new particle rates in the burn-in stage, and by the end of burn-in, we should see stationarity in the parameter estimates.</p>
</div>
</div>
<div id="genppdatafunc" class="section level2">
<h2><span class="header-section-number">3.5</span> Simulating Posterior Predictive Data</h2>
<p>We can generate posterior predictive data by setting <code>sample = TRUE</code> in our log-likelihood function to generate response times and responses <i>given</i> the posterior parameter estimates for each subject. To do this, we use the <code>gen_pp_data</code> function below, which calls the log-likelihood function embedded in our <code>sampled</code> object. The <code>gen_pp_data</code> function takes four arguments:</p>
<ul>
<li><code>sampled</code>: is the object/output from the PMwG sampler</li>
<li><code>n</code>: the number of posterior samples</li>
<li><code>ll_func =</code>: the log-likelihood function embedded in the <code>sampled</code> object</li>
<li><code>rbind.data =</code>: bind the rows of each predictive sample into a rectangular array, or leave as a list.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gen_pp_data &lt;-<span class="st"> </span><span class="cf">function</span> (sampled, n, <span class="dt">ll_func =</span> sampled<span class="op">$</span>ll_func, <span class="dt">rbind.data =</span> <span class="ot">TRUE</span>) {
  sampled_stage &lt;-<span class="st"> </span><span class="kw">length</span>(sampled<span class="op">$</span>samples<span class="op">$</span>stage[sampled<span class="op">$</span>samples<span class="op">$</span>stage <span class="op">==</span><span class="st"> &quot;sample&quot;</span>])
  iterations &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dt">from =</span> (sampled<span class="op">$</span>samples<span class="op">$</span>idx <span class="op">-</span><span class="st"> </span>sampled_stage),
                            <span class="dt">to =</span> sampled<span class="op">$</span>samples<span class="op">$</span>idx,
                            <span class="dt">length.out =</span> n))
  data &lt;-<span class="st"> </span>sampled<span class="op">$</span>data
  S &lt;-<span class="st"> </span>sampled<span class="op">$</span>n_subjects
  pp_data &lt;-<span class="st"> </span><span class="kw">list</span>()
  
    <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>S){
       <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;subject&quot;</span>, s))
      <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(iterations)) {
        <span class="kw">print</span>(i)
        x &lt;-<span class="st"> </span>sampled<span class="op">$</span>samples<span class="op">$</span>alpha[, s, iterations[i]]
        <span class="kw">names</span>(x) &lt;-<span class="st"> </span>sampled<span class="op">$</span>par_names
        out &lt;-<span class="st"> </span><span class="kw">ll_func</span>(<span class="dt">x =</span> x, 
                       <span class="dt">data =</span> data[data<span class="op">$</span>subject <span class="op">==</span><span class="st"> </span><span class="kw">unique</span>(data<span class="op">$</span>subject)[s], ],
                       <span class="dt">sample =</span> <span class="ot">TRUE</span>)
        
        <span class="cf">if</span> (i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>){
          pp_data[[s]] =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">pp_iter =</span> i, out)
        }
        <span class="cf">else</span> {
          pp_data[[s]] =<span class="st"> </span><span class="kw">rbind</span>(pp_data[[s]],
                         <span class="kw">cbind</span>(<span class="dt">pp_iter =</span> i, out))
        }
      }
    }
  
    <span class="cf">if</span> (rbind.data){
    tidy_pp_data &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, pp_data)  
    <span class="kw">return</span>(tidy_pp_data)
    }
    <span class="cf">else</span> {
      <span class="kw">return</span>(pp_data)
    }
}</code></pre></div>
<p>We generate 20 posterior predictive data samples.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pp_data_3b &lt;-<span class="st"> </span><span class="kw">gen_pp_data</span>(sampled, <span class="dt">n =</span> <span class="dv">20</span>)</code></pre></div>
<p>The returned data is a matrix with the same dimensions and names as <code>forstmann</code> – with the addition of <code>pp_iter</code> column. <code>pp_iter</code> is the iteration of posterior sample (in this example <code>i = 1:20</code>) for the corresponding subject. We now have two matrices based on samples from either model. The response (<code>resp</code>) and response time (<code>rt</code>) columns now contain posterior predictive data.</p>
<p>In the next section, we will use the posterior predictive data to assess descriptive adequacy.</p>
<div id="assessing-descriptive-adequacy-goodness-of-fit" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Assessing Descriptive Adequacy (goodness of fit)</h3>
<p>Now we will plot the posterior predictive data against the observed data. In the section below we compare observed RTs against predicted RTs, which is common for RT modelling; however, the code could also be modified for different types of data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Subject x condition Q25, median and Q75 respone time + mean accuracy </span>
<span class="co"># Forstmann dataset</span>
pq3b &lt;-<span class="st"> </span>forstmann <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(condition, subject) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt), 
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span>  <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Subject x condition Q25, median and Q75 respone time for posterior predictive data</span>
pp_pq3b &lt;-<span class="st"> </span>pp_data_3b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, subject) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt), 
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span> <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Combine data with posterior predictive data and add data source</span>
pq3b &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(<span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;data&quot;</span>, <span class="kw">nrow</span>(pq3b)), pq3b),
                <span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;model&quot;</span>, <span class="kw">nrow</span>(pp_pq3b)), pp_pq3b)
                )

<span class="co"># Mean Q25, median, Q4 and accuracy for data and posterior predictive data</span>
av_pq3b &lt;-<span class="st"> </span>pq3b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(src, condition) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Variances of posterior samples</span>
pp_var3b &lt;-<span class="st"> </span>pq3b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(src <span class="op">!=</span><span class="st"> &quot;data&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, src) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Convert source column to a factor and add labels</span>
av_pq3b<span class="op">$</span>src &lt;-<span class="st"> </span><span class="kw">factor</span>(av_pq3b<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>)
                    )

pp_varsrc3b &lt;-<span class="st"> </span><span class="kw">factor</span>(pp_var3b<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>)
                    )
<span class="co"># Rename conditions</span>
<span class="kw">levels</span>(av_pq3b<span class="op">$</span>condition) &lt;-
<span class="st">  </span><span class="kw">levels</span>(pp_var3b<span class="op">$</span>condition) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Accuracy&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Speed&quot;</span>)

<span class="co"># Convert rt to milliseconds and acc to percentage</span>
av_pq3b<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>av_pq3b<span class="op">$</span>acc
pp_var3b<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>pp_var3b<span class="op">$</span>acc
av_pq3b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>av_pq3b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]
pp_var3b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>pp_var3b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/ppdataplotarrg3b-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="evaluating-different-models---single-threshold-lba" class="section level2">
<h2><span class="header-section-number">3.6</span> Evaluating different models - single threshold LBA</h2>
<p>In this section we will evaluate different LBA models. For each model, we will the estimate posterior distribution, generate posterior predictive data, and then compare those against observed data.</p>
<p>In this example we assume that participants’s level of caution does not change with emphasis instructions i.e. the threshold for <code>Accuracy</code>, <code>Neutral</code>, and <code>Speed</code> conditions is the same. We will call this our “single threshold LBA model”. The single threshold LBA model’s log-likelihood has one <code>b</code> parameter, instead of three (see line 18, 31 and 64 below). For each model, we will estimate the posterior distribution, generate posterior predictive data, and then compare these against the empirical data.</p>
<p>For brevity, we specify only the ‘<i>fast</i>’ log-likelihood function for the single threshold model.</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">fast_lba_ll1b &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  
  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  
  <span class="cf">if</span> (sample) { 
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
      A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
      b =<span class="st"> </span>x[<span class="st">&quot;b&quot;</span>] <span class="op">+</span><span class="st"> </span>A
      vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
      ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
      t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
      s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
      <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
        vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
      } <span class="cf">else</span> {
        vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
      }
      
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    } 
  } <span class="cf">else</span> {

  vlist =<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;v.1&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data)), 
               <span class="st">&quot;v.2&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data)))
  
  
  <span class="cf">for</span> (c <span class="cf">in</span> <span class="kw">levels</span>(data<span class="op">$</span>condition)) {
    <span class="cf">for</span> (s <span class="cf">in</span> <span class="kw">levels</span>(data<span class="op">$</span>stim)) {
      use &lt;-<span class="st"> </span>data<span class="op">$</span>condition <span class="op">==</span><span class="st"> </span>c <span class="op">&amp;</span><span class="st"> </span>data<span class="op">$</span>stim <span class="op">==</span><span class="st"> </span>s
        vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
        ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
        <span class="cf">if</span> (s <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
          vlist<span class="op">$</span>v.<span class="dv">1</span>[use] =<span class="st"> </span>vc
          vlist<span class="op">$</span>v.<span class="dv">2</span>[use] =<span class="st"> </span>ve
        } <span class="cf">else</span> {
          vlist<span class="op">$</span>v.<span class="dv">1</span>[use] =<span class="st"> </span>ve
          vlist<span class="op">$</span>v.<span class="dv">2</span>[use] =<span class="st"> </span>vc
        }
    }
  }
    out &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt,
                <span class="dt">response =</span> data<span class="op">$</span>resp,
                <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                <span class="dt">b =</span> x[<span class="st">&quot;b&quot;</span>] <span class="op">+</span><span class="st"> </span>x[<span class="st">&quot;A&quot;</span>],
                <span class="dt">mean_v =</span> vlist,
                <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                <span class="dt">silent =</span> <span class="ot">TRUE</span>)
    }
  
  <span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    out&lt;-<span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">pmax</span>(out, <span class="fl">1e-10</span>)))
    <span class="kw">return</span>(out)
  }
}</code></pre></td></tr></table></div>
<div id="pmwg-framework-for-a-single-threshold-model" class="section level3">
<h3><span class="header-section-number">3.6.1</span> PMwG framework for a single threshold model</h3>
<p>The PMwG sampler procedure remains the same for all models. For our three threshold LBA model, we need the updated log-likelihood function from above, an updated parameter vector, start points and priors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the log-likelihood script</span>
<span class="kw">source</span>(<span class="dt">file =</span> <span class="st">&quot;fast_lba_ll1b.R&quot;</span>)

<span class="co"># Specify the parameter vector with single threshold (b) parameter</span>
pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;b&quot;</span>,<span class="st">&quot;vc&quot;</span>,<span class="st">&quot;ve&quot;</span>,<span class="st">&quot;t0&quot;</span>)

<span class="co"># Specifiy a priors list</span>
priors &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">theta_mu =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(pars)),
  <span class="dt">theta_sig =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(pars)))
)

<span class="co"># Setup your sampler object - include your data, parameter vector, </span>
<span class="co"># priors and log-likelihood function</span>
<span class="co"># Note: Your log-likelihood function must be loaded before this point</span>
sampler &lt;-<span class="st"> </span><span class="kw">pmwgs</span>(
  <span class="dt">data =</span> forstmann,
  <span class="dt">pars =</span> pars,
  <span class="dt">prior =</span> priors,
  <span class="dt">ll_func =</span> fast_lba_ll1b
)

<span class="co"># Start points are not included in this example</span>
<span class="co"># Initiatlise the sampler</span>
sampler &lt;-<span class="st"> </span><span class="kw">init</span>(sampler)

<span class="co"># Burn-in stage</span>
burned &lt;-<span class="st"> </span><span class="kw">run_stage</span>(sampler, 
                    <span class="dt">stage =</span> <span class="st">&quot;burn&quot;</span>,
                    <span class="dt">iter =</span> <span class="dv">500</span>,
                    <span class="dt">particles =</span> <span class="dv">1000</span>,
                    <span class="dt">epsilon =</span> .<span class="dv">5</span>)
<span class="co"># Adaptation stage</span>
adapted &lt;-<span class="st"> </span><span class="kw">run_stage</span>(burned,
                     <span class="dt">stage =</span> <span class="st">&quot;adapt&quot;</span>,
                     <span class="dt">iter =</span> <span class="dv">10000</span>,
                     <span class="dt">particles =</span> <span class="dv">1000</span>,
                     <span class="dt">epsilon =</span> .<span class="dv">5</span>)
<span class="co"># Sample stage</span>
sampled &lt;-<span class="st"> </span><span class="kw">run_stage</span>(adapted, 
                     <span class="dt">stage =</span> <span class="st">&quot;sample&quot;</span>,
                     <span class="dt">iter =</span> <span class="dv">1000</span>,
                     <span class="dt">particles =</span> <span class="dv">200</span>,
                     <span class="dt">epsilon =</span> .<span class="dv">5</span>)</code></pre></div>
<p><b>Note:</b> we keep the priors, start points, number of iterations and particles the same as our three threshold LBA model, so there is no bias for either model.</p>
</div>
</div>
<div id="checking-descriptive-adequacy-of-1b-model." class="section level2">
<h2><span class="header-section-number">3.7</span> Checking Descriptive Adequacy of 1b model.</h2>
<p>The checking procedure below is the same as the three threshold LBA model, except we use the single threshold LBA model’s <code>sampled</code> object/data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;forstmann1b_sampled.RData&quot;</span>)</code></pre></div>
<p>As we did for the three threshold LBA model, we generate 20 posterior predictive data samples. Note: this function is from section <a href="forstmannChapter.html#genppdatafunc">3.5</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pp_data_1b &lt;-<span class="st"> </span><span class="kw">gen_pp_data</span>(sampled, <span class="dt">n =</span> <span class="dv">20</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Subject x condition Q25, median and Q75 respone time + mean accuracy</span>
<span class="co"># Forstmann dataset</span>
pq1b &lt;-<span class="st"> </span>forstmann <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, subject) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt),
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span>  <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Subject x condition Q25, median and Q75 respone time for posterior predictive data</span>
pp_pq1b &lt;-<span class="st"> </span>pp_data_1b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, subject) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt),
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span> <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Combine data with posterior predictive data and add data source</span>
pq1b &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(<span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;data&quot;</span>, <span class="kw">nrow</span>(pq1b)), pq1b),
                <span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;model&quot;</span>, <span class="kw">nrow</span>(pp_pq1b)), pp_pq1b)
                )

<span class="co"># Mean Q25, median, Q4 and accuracy for data and posterior predictive data</span>
av_pq1b &lt;-<span class="st"> </span>pq1b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(src, condition) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Variances of posterior samples</span>
pp_var1b &lt;-<span class="st"> </span>pq1b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(src <span class="op">!=</span><span class="st"> &quot;data&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, src) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Convert source column to a factor and add labels</span>
av_pq1b<span class="op">$</span>src &lt;-<span class="st"> </span><span class="kw">factor</span>(av_pq1b<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>)
                    )

pp_varsrc1b &lt;-<span class="st"> </span><span class="kw">factor</span>(pp_var1b<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>)
                    )
<span class="co"># Rename conditions</span>
<span class="kw">levels</span>(av_pq1b<span class="op">$</span>condition) &lt;-
<span class="st">  </span><span class="kw">levels</span>(pp_var1b<span class="op">$</span>condition) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Accuracy&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Speed&quot;</span>)

<span class="co"># Convert rt to milliseconds and acc to percentage</span>
av_pq1b<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>av_pq1b<span class="op">$</span>acc
pp_var1b<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>pp_var1b<span class="op">$</span>acc
av_pq1b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>av_pq1b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]
pp_var1b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>pp_var1b[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/ppdataplot1b-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="forstMC" class="section level2">
<h2><span class="header-section-number">3.8</span> Model Comparison</h2>
<p>In this section, we are going to compare the three threshold model and the single threshold model for the <span class="citation">Forstmann et al. (<a href="#ref-forstmann2008striatum">2008</a>)</span> data to determine which model best represents the data. We begin by using a graphical method i.e. plotting the modelled data against the observed data.</p>
<div id="assessing-descriptive-adequacy-graphically" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Assessing Descriptive Adequacy Graphically</h3>
<p>We can assess descriptive adequacy graphically by plotting the observed data, three threshold model and single threshold model data on a single plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Subject x condition Q25, median and Q75 respone time + mean accuracy </span>
<span class="co"># Forstmann data</span>
pq &lt;-<span class="st"> </span>forstmann <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, subject) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt),
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span>  <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Subject x condition Q25, median and Q75 respone time for posterior predictive data</span>
<span class="co">#3b model</span>
pp_pq3b &lt;-<span class="st"> </span>pp_data_3b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, subject) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt), 
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span> <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )
<span class="co"># Subject x condition Q25, median and Q75 respone time for posterior predictive data </span>
<span class="co">#1b model</span>
pp_pq1b &lt;-<span class="st"> </span>pp_data_1b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, subject) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt),
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span> <span class="kw">mean</span>(<span class="kw">ifelse</span>(stim <span class="op">==</span><span class="st"> </span>resp, <span class="dv">1</span>, <span class="dv">0</span>)),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Combine data with posterior predictive data for 1b and 3b models + add data source</span>
pqall &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(<span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;data&quot;</span>, <span class="kw">nrow</span>(pq)), pq),
                <span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;3b&quot;</span>, <span class="kw">nrow</span>(pp_pq3b)), pp_pq3b),
                <span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;1b&quot;</span>, <span class="kw">nrow</span>(pp_pq1b)), pp_pq1b)
                )

<span class="co"># Mean Q25, median, Q4 and accuracy for data and posterior predictive data</span>
av_pq &lt;-<span class="st"> </span>pqall <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(src, condition) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Variances of posterior samples</span>
pp_var &lt;-<span class="st"> </span>pqall <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(src <span class="op">!=</span><span class="st"> &quot;data&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, src) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Convert source column to a factor and add labels</span>
av_pq<span class="op">$</span>src &lt;-<span class="st"> </span><span class="kw">factor</span>(av_pq<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;3b&quot;</span>, <span class="st">&quot;data&quot;</span>, <span class="st">&quot;1b&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;3b&quot;</span>, <span class="st">&quot;data&quot;</span>, <span class="st">&quot;1b&quot;</span>)
                    )

pp_varsrc &lt;-<span class="st"> </span><span class="kw">factor</span>(pp_var<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;3b&quot;</span>, <span class="st">&quot;data&quot;</span>, <span class="st">&quot;1b&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;3b&quot;</span>, <span class="st">&quot;data&quot;</span>, <span class="st">&quot;1b&quot;</span>)
                    )
<span class="co"># Rename conditions</span>
<span class="kw">levels</span>(av_pq<span class="op">$</span>condition) &lt;-
<span class="st">  </span><span class="kw">levels</span>(pp_var<span class="op">$</span>condition) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Accuracy&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Speed&quot;</span>)

<span class="co"># Convert rt to milliseconds and acc to percentage</span>
av_pq<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>av_pq<span class="op">$</span>acc
pp_var<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>pp_var<span class="op">$</span>acc
av_pq[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>av_pq[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]
pp_var[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>pp_var[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/ppdataplotModelComp-1.png" width="672" style="display: block; margin: auto;" /> The plots show that values in the three threshold model (red circles) better describe the data than the single threshold model (blue circles).</p>
</div>
<div id="forstDIC" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Model comparison via DIC</h3>
<p>Another method of model comparison is using an information criterion such as the deviance information criterion (DiC). Here we provide a function for calculating DIC. <b>Note:</b> we recommend using marginal likelihood (Bayes factors) instead of DIC for model selection. For more information, see this paper on <a href="https://link.springer.com/article/10.3758/s13428-020-01348-w">estimating the Marginal Likelihood via importance sampling</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pmwg_DIC &lt;-<span class="st"> </span><span class="cf">function</span>(sampled, <span class="dt">pD =</span> <span class="ot">FALSE</span>){
  <span class="co"># Identify number of subjects</span>
  nsubj &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(sampled<span class="op">$</span>data<span class="op">$</span>subject))
 
  <span class="co"># Mean log-likelihood of the overall (sampled-stage) model, for each subject</span>
  mean_ll &lt;-<span class="st"> </span><span class="kw">apply</span>(sampled<span class="op">$</span>samples<span class="op">$</span>subj_ll[, sampled<span class="op">$</span>samples<span class="op">$</span>stage <span class="op">==</span><span class="st"> &quot;sample&quot;</span>],
                   <span class="dv">1</span>,
                   mean)
 
  <span class="co"># Mean of each parameter across iterations.</span>
  <span class="co"># Keep dimensions for parameters and subjects</span>
  mean_pars &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(sampled<span class="op">$</span>samples<span class="op">$</span>alpha[,, sampled<span class="op">$</span>samples<span class="op">$</span>stage <span class="op">==</span><span class="st"> &quot;sample&quot;</span>],
                       <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,
                       mean))

 
  <span class="co"># Name &#39;mean_pars&#39; so it can be used by the log_like function</span>
  <span class="kw">colnames</span>(mean_pars) &lt;-<span class="st"> </span>sampled<span class="op">$</span>par_names
 
  <span class="co"># log-likelihood for each subject using their mean parameter vector</span>
  mean_pars_ll &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">ncol</span>(mean_pars))
  
  data &lt;-<span class="st"> </span><span class="kw">transform</span>(sampled<span class="op">$</span>data, 
                    <span class="dt">subject =</span> <span class="kw">match</span>(subject, <span class="kw">unique</span>(subject)))
  
  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsubj) {
    mean_pars_ll[j] &lt;-<span class="st"> </span>sampled<span class="op">$</span><span class="kw">ll_func</span>(mean_pars[j, ],
                                       <span class="dt">data =</span> data[data<span class="op">$</span>subject <span class="op">==</span><span class="st"> </span>j,],
                                       <span class="dt">sample =</span> <span class="ot">FALSE</span>)
  }
 
  <span class="co"># Effective number of parameters</span>
  pD &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>mean_ll <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>mean_pars_ll)
 
  <span class="co"># Deviance Information Criterion</span>
  DIC &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>mean_ll <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>mean_pars_ll)
 
  <span class="cf">if</span> (pD){
    <span class="kw">return</span>(<span class="kw">c</span>(<span class="st">&quot;DIC &quot;</span> =<span class="st"> </span>DIC, <span class="st">&quot; Effective parameters&quot;</span> =<span class="st"> </span>pD))
  }<span class="cf">else</span>{
    <span class="kw">return</span>(DIC)
  }
   
}</code></pre></div>
<p>We calculate the DIC value for each model by passing the <code>sampled</code> object into the <code>pmwgDIC</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;forstmann3b_sampled.RData&quot;</span>)
sampled3b &lt;-<span class="st"> </span>sampled
<span class="kw">pmwg_DIC</span>(<span class="dt">sampled =</span> sampled3b)</code></pre></div>
<pre><code>             DIC   Effective parameters 
     -15381.53339              91.76401 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;forstmann1b_sampled.RData&quot;</span>)
sampled1b &lt;-<span class="st"> </span>sampled
<span class="kw">pmwg_DIC</span>(<span class="dt">sampled =</span> sampled1b)</code></pre></div>
<pre><code>             DIC   Effective parameters 
     -10778.94733              44.84388 </code></pre>
<p>The three threshold model has a lower DIC value than the single threshold model, indicating a better explanation of the data. Based on the graphical evidence and the DIC, we can be confident that the three threshold model (i.e the model where threshold is varied with speed and accuracy instructions) is a better fit to our data than the single threshold model.</p>
</div>
</div>
<div id="LBAllcheck" class="section level2">
<h2><span class="header-section-number">3.9</span> Checking the LBA log-likelihood function</h2>
<p>Here we show two ways to test your log-likelihood function. This method is not fail-safe, however, it allows you to establish whether your function operates as intended.</p>
<p>We will use the three threshold LBA model log-likelihood function in the following examples.</p>
<div id="test-one-do-changes-in-parameter-values-cause-changes-in-the-returned-log-likelihood" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Test one: Do changes in parameter values cause changes in the returned log-likelihood?</h3>
<p>We will test our log-likelihood functions by passing a parameter vector (<code>x</code>) of plausible, arbitrary values, followed by a second parameter vector with different, plausible, arbitrary values. If the log-likehood functions are functioning correctly, we should see the log-likelihood value change with the change in parameter values. We may also wish to check that unrealistic parameter values are effectively dealt with (for example, <code>t0</code> should not be able to be greater than any RTs).</p>
<p>Let’s compare the output from the trialwise log-likelihood function in section <a href="forstmannChapter.html#theLLFunc">3.3</a> and the fast log-likelihood function in section <a href="forstmannChapter.html#fstLBALL">3.3.3</a> :</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(<span class="dt">A =</span> <span class="dv">2</span>,
           <span class="dt">b.1 =</span> <span class="dv">2</span>, 
           <span class="dt">b.2 =</span> <span class="dv">1</span>, 
           <span class="dt">b.3 =</span> .<span class="dv">5</span>,
           <span class="dt">vc =</span> <span class="dv">4</span>,
           <span class="dt">ve =</span> <span class="dv">2</span>,
           <span class="dt">t0 =</span> .<span class="dv">18</span>
           )
         )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tw_lba_ll</span>(x, forstmann, <span class="dt">sample =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] -44505.89</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fast_lba_ll3b</span>(x, forstmann, <span class="dt">sample =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] -44505.89</code></pre>
<p>Great – the log-likelihoods are the same. Now let’s change the parameter values, in particular, the three threshold parameters, and see if the log-likelihood changes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(<span class="dt">A =</span> <span class="dv">2</span>,
           <span class="dt">b.1 =</span> <span class="dv">1</span>,
           <span class="dt">b.2 =</span> <span class="dv">3</span>,
           <span class="dt">b.3 =</span> <span class="dv">3</span>,
           <span class="dt">vc =</span> <span class="dv">4</span>,
           <span class="dt">ve =</span> <span class="dv">2</span>,
           <span class="dt">t0 =</span> .<span class="dv">18</span>
           )
         )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tw_lba_ll</span>(x, forstmann, <span class="dt">sample =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] -202667.3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fast_lba_ll3b</span>(x, forstmann, <span class="dt">sample =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] -202667.3</code></pre>
<p>These log-likelihoods are lower than the previous two, so the parameter (<code>x</code>) values are less accurate given the data. Notice how we can also use this process to check the fast, efficient log-likelihood function (<code>fast_lba_ll3b</code>) against the trialwise function (<code>tw_lba_ll</code>). Given the same data and parameter values - they should give the same output, as we see above.</p>
<p><b>Note</b>: We only changed some named (<code>x</code>) parameter values. You could perform a thorough check by changing one parameter value at a time and see if there is a change in the log-likelihood.</p>
<p>This is a good first check to see if our log-likelihood is behaving as it should; change in log-likelihood value with a change in parameter values. However, our log-likelihood functions may contain inconsistencies, which leads us onto our second check.</p>
</div>
<div id="testing-whether-data-generating-parameter-values-have-the-highest-likelihood" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Testing whether data generating parameter values have the highest likelihood</h3>
<p>A more comprehensive way to test your log-likelihood function is to generate ‘synthetic’ data for which you know the data generating values. This is a form of ‘parameter recovery’, where you run the sampler on generated data and plot the log-likelihood change as x values move away from your data generating parameter x-values. If the data generating x-values have the highest log-likelihood, then it is likely that your function is working as intended.</p>
<p>There are two steps to this method:</p>
<ol style="list-style-type: decimal">
<li>Assign values to parameters of the model - these are known as the generating values. <br><b>Note</b>: ensure these are sensible values - for example in the LBA, we want the drift rate for the mismatch/error accumulator (<code>ve</code>) to be smaller than the match/correct accumulator (<code>vc</code>) and the non-decision time parameter <code>t0</code> should not be too large.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(<span class="dt">A =</span> <span class="dv">2</span>,
           <span class="dt">b.1 =</span> <span class="dv">1</span>,
           <span class="dt">b.2 =</span> <span class="dv">3</span>,
           <span class="dt">b.3 =</span> <span class="dv">3</span>,
           <span class="dt">vc =</span> <span class="dv">4</span>,
           <span class="dt">ve =</span> <span class="dv">2</span>,
           <span class="dt">t0 =</span> .<span class="dv">18</span>
           )
         )</code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Produce profile plots to compare the log-likelihood of the <code>x</code> parameter values against nearby values in the ‘synethetic’ data. You can write your own function for this, or use the function below.</li>
</ol>
<p>Our plotting function takes two arguments:</p>
<ul>
<li><code>sampler</code> is the initiated sampler object. See section <a href="forstmannChapter.html#run-sampler">3.4.2</a> above.</li>
<li><code>generating_values = Null</code> create ‘generating values’ based on <code>theta_mu</code> from sampler object or use values output from the log-likelihood function.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">profilePlot &lt;-<span class="st"> </span><span class="cf">function</span>(sampler, <span class="dt">generating_values =</span> <span class="ot">NULL</span>){
  <span class="cf">if</span>(<span class="kw">is.null</span>(generating_values)){
    <span class="co"># Create generating values based on theta_mu</span>
    generating_values &lt;-<span class="st"> </span>sampler<span class="op">$</span>samples<span class="op">$</span>theta_mu
    <span class="kw">names</span>(generating_values) &lt;-<span class="st"> </span>sampler<span class="op">$</span>par_names
  } <span class="cf">else</span>{
    <span class="kw">names</span>(generating_values) &lt;-<span class="st"> </span>sampler<span class="op">$</span>par_names
  }
  <span class="co">#Create test data set. We use a tenth of the total data for speed</span>
  test &lt;-<span class="st"> </span>sampler<span class="op">$</span><span class="kw">ll_func</span>(<span class="dt">x =</span> generating_values,
                  <span class="dt">data =</span> sampler<span class="op">$</span>data[<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">nrow</span>(sampler<span class="op">$</span>data) <span class="op">/</span><span class="st"> </span><span class="dv">3</span>)),],
                  <span class="dt">sample =</span> <span class="ot">TRUE</span>)
  <span class="co"># n_values = number of values to test and plot. </span>
  n_values &lt;-<span class="st"> </span><span class="dv">9</span>
  tmp &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dt">dim =</span> <span class="kw">c</span>(n_values, sampler<span class="op">$</span>n_pars))
  <span class="co"># Scale for increment. Can be made smaller or larger.</span>
  <span class="co"># Here we use theta_mu - .2 to theta_mu + .2, with n_values length</span>
  increment &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="op">-</span>.<span class="dv">2</span>,
                   <span class="dt">to =</span> .<span class="dv">2</span>,
                   <span class="dt">length.out =</span> n_values)
  
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>sampler<span class="op">$</span>n_pars){
    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_values){
      <span class="co"># Use all generating values except the current parameter being tested</span>
      test_values &lt;-<span class="st"> </span>generating_values
      <span class="co"># Change the current parameter by adding the increment</span>
      test_values[i] &lt;-<span class="st"> </span>generating_values[i] <span class="op">+</span><span class="st"> </span>increment[j]
      <span class="co"># Test the likelihood given these new values and the test data</span>
      tmp[j, i] &lt;-<span class="st"> </span>sampler<span class="op">$</span><span class="kw">ll_func</span>(<span class="dt">x =</span> test_values, 
                                   <span class="dt">data =</span> test,
                                   <span class="dt">sample =</span> <span class="ot">FALSE</span>)
    }
  }
  <span class="co"># Prepare output for plotting</span>
  <span class="kw">colnames</span>(tmp) &lt;-<span class="st"> </span>sampler<span class="op">$</span>par_names
  tmp &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(tmp)
  tmp &lt;-<span class="st"> </span>tidyr<span class="op">::</span><span class="kw">pivot_longer</span>(tmp, 
                             <span class="kw">everything</span>(),
                             <span class="dt">names_to =</span> <span class="st">&quot;pars&quot;</span>,
                             <span class="dt">values_to =</span> <span class="st">&quot;likelihood&quot;</span>)
  tmp<span class="op">$</span>increment &lt;-<span class="st"> </span><span class="kw">rep</span>(increment, 
                       <span class="dt">each =</span> sampler<span class="op">$</span>n_pars)
  <span class="co"># Plot values for each parameter</span>
  ggplot2<span class="op">::</span><span class="kw">ggplot</span>(tmp, 
                  <span class="kw">aes</span>(<span class="dt">x =</span> increment,
                      <span class="dt">y =</span> likelihood)
                  ) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span>pars,
               <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">axis.title.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">face =</span> <span class="st">&#39;bold&#39;</span>),
        <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">14</span>),
        <span class="dt">axis.title.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">face =</span> <span class="st">&#39;bold&#39;</span>),
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">14</span>)
        ) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Increment&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Likelihood&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>,
               <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>,
               <span class="dt">alpha =</span> <span class="fl">0.3</span>)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">profilePlot</span>(<span class="dt">sampler =</span> sampler, <span class="dt">generating_values =</span> x)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/loadSamplahObj-1.png" width="672" /></p>
<p>The red line indicates the true generating parameter value (i.e. the data generating values for the parameters) have the best (highest) likelihoods.</p>
<p>Note: The plots above do not tell you if your log-likelihood is correct in the sense that you have written a log-likelihood for the model you actually want to test. The plots allow you to determine if your function is functioning as intended.</p>
<p>Below is output from a function with a potential error. We can see that the red lines indicating the generating parameter values (i.e. the data generating values for the parameters) do not have the best (highest) likelihoods. Plots with flat lines for parameter values would also be indicative of an error somewhere within your log-likelihood code.</p>
<p><img src="bookdown-demo_files/figure-html/dodgellplots-1.png" width="672" /></p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-brown2008simplest">
<p>Brown, Scott, and Andrew Heathcote. 2008. “The Simplest Complete Model of Choice Response Time: Linear Ballistic Accumulation.” <em>Cognitive Psychology</em> 57 (3). Elsevier: 153–78.</p>
</div>
<div id="ref-forstmann2008striatum">
<p>Forstmann, Birte U, Gilles Dutilh, Scott Brown, Jane Neumann, D Yves Von Cramon, K Richard Ridderinkhof, and Eric-Jan Wagenmakers. 2008. “Striatum and Pre-Sma Facilitate Decision-Making Under Time Pressure.” <em>Proceedings of the National Academy of Sciences</em> 105 (45). National Acad Sciences: 17538–42.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The parameters you list in the <code>pars</code> vector <b>must</b> match those included in your log-likelihood function i.e. they must have the same names and the same number of parameters. Refer to the <a href="troubleshoot.html#troubleshoot">troubleshooting section</a> for more detail.<a href="forstmannChapter.html#fnref1">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pmwg-sampler-and-signal-detection-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-forstLBA.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
