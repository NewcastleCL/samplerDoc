<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 PMwG sampler with the Linear Ballistic Accumulator and a complex experiment design | Particle Based Samplers for MCMC</title>
  <meta name="description" content="Particle Based Sampler for MCMC" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 PMwG sampler with the Linear Ballistic Accumulator and a complex experiment design | Particle Based Samplers for MCMC" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Particle Based Sampler for MCMC" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 PMwG sampler with the Linear Ballistic Accumulator and a complex experiment design | Particle Based Samplers for MCMC" />
  
  <meta name="twitter:description" content="Particle Based Sampler for MCMC" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="forstmannChapter.html"/>
<link rel="next" href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PMwG Samplers Package</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to particle based sampler for MCMC</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#assumed-knowledge"><i class="fa fa-check"></i><b>1.1</b> Assumed knowledge</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#why-would-you-use-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.2</b> Why would you use Particle Metropolis within Gibbs sampling?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#the-assumed-hierarchical-structure"><i class="fa fa-check"></i><b>1.3</b> The assumed hierarchical structure</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#what-particle-metropolis-within-gibbs-sampling-provides"><i class="fa fa-check"></i><b>1.4</b> What Particle Metropolis within Gibbs sampling provides</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#what-is-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.5</b> What is Particle Metropolis within Gibbs sampling?</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#generating-proposals-in-pmwg-sampling-using-particle-metropolis"><i class="fa fa-check"></i><b>1.6</b> Generating proposals in PMwG sampling using Particle Metropolis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html"><i class="fa fa-check"></i><b>2</b> PMwG sampler and Signal Detection Theory</a><ul>
<li class="chapter" data-level="2.0.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline"><i class="fa fa-check"></i><b>2.0.1</b> Signal Detection Theory analysis of lexical decision task</a></li>
<li class="chapter" data-level="2.0.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#SDTLLFun"><i class="fa fa-check"></i><b>2.0.2</b> The log-likelihood function</a></li>
<li class="chapter" data-level="2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#testing-the-sdt-log-likelihood-function"><i class="fa fa-check"></i><b>2.1</b> Testing the SDT log-likelihood function</a></li>
<li class="chapter" data-level="2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtWag"><i class="fa fa-check"></i><b>2.2</b> SDT log-likelihood function for Wagenmakers experiment</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#description-of-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2.1</b> Description of Wagenmakers experiment</a></li>
<li class="chapter" data-level="2.2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#computation-time-of-the-log-likelihood-function"><i class="fa fa-check"></i><b>2.2.2</b> Computation time of the log-likelihood function</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtPMwG"><i class="fa fa-check"></i><b>2.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="2.3.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>2.3.1</b> Model start points</a></li>
<li class="chapter" data-level="2.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#run-sdtsampler"><i class="fa fa-check"></i><b>2.3.2</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#check-the-sampling-process"><i class="fa fa-check"></i><b>2.4</b> Check the sampling process</a></li>
<li class="chapter" data-level="2.5" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#simulating-posterior-data"><i class="fa fa-check"></i><b>2.5</b> Simulating posterior data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="forstmannChapter.html"><a href="forstmannChapter.html"><i class="fa fa-check"></i><b>3</b> PMwG sampler and sequential sampling models</a><ul>
<li class="chapter" data-level="3.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#the-speed-accuracy-tradeoff-in-perceptual-decisions"><i class="fa fa-check"></i><b>3.1</b> The speed-accuracy tradeoff in perceptual decisions</a></li>
<li class="chapter" data-level="3.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#LBAParameters"><i class="fa fa-check"></i><b>3.2</b> Linear Ballistic Accumulator Parameters</a></li>
<li class="chapter" data-level="3.3" data-path="forstmannChapter.html"><a href="forstmannChapter.html#theLLFunc"><i class="fa fa-check"></i><b>3.3</b> The log-likelihood function</a><ul>
<li class="chapter" data-level="3.3.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#what-is-a-log-likelihood-function"><i class="fa fa-check"></i><b>3.3.1</b> What is a log-likelihood function?</a></li>
<li class="chapter" data-level="3.3.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#writing-the-log-likelihood-function-for-the-forstmann-data-set"><i class="fa fa-check"></i><b>3.3.2</b> Writing the log-likelihood function for the Forstmann data set</a></li>
<li class="chapter" data-level="3.3.3" data-path="forstmannChapter.html"><a href="forstmannChapter.html#fstLBALL"><i class="fa fa-check"></i><b>3.3.3</b> Fast LBA Log-likelihood Function</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="forstmannChapter.html"><a href="forstmannChapter.html#pmwg-framework"><i class="fa fa-check"></i><b>3.4</b> PMwG Framework</a><ul>
<li class="chapter" data-level="3.4.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#lbaStartPts"><i class="fa fa-check"></i><b>3.4.1</b> Model start points</a></li>
<li class="chapter" data-level="3.4.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#run-sampler"><i class="fa fa-check"></i><b>3.4.2</b> Running the sampler</a></li>
<li class="chapter" data-level="3.4.3" data-path="forstmannChapter.html"><a href="forstmannChapter.html#estSet"><i class="fa fa-check"></i><b>3.4.3</b> Determining estimation settings for the PMwG sampler</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="forstmannChapter.html"><a href="forstmannChapter.html#genppdatafunc"><i class="fa fa-check"></i><b>3.5</b> Simulating Posterior Predictive Data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#assessing-descriptive-adequacy-goodness-of-fit"><i class="fa fa-check"></i><b>3.5.1</b> Assessing Descriptive Adequacy (goodness of fit)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="forstmannChapter.html"><a href="forstmannChapter.html#evaluating-different-models---single-threshold-lba"><i class="fa fa-check"></i><b>3.6</b> Evaluating different models - single threshold LBA</a><ul>
<li class="chapter" data-level="3.6.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#pmwg-framework-for-a-single-threshold-model"><i class="fa fa-check"></i><b>3.6.1</b> PMwG framework for a single threshold model</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="forstmannChapter.html"><a href="forstmannChapter.html#checking-descriptive-adequacy-of-1b-model."><i class="fa fa-check"></i><b>3.7</b> Checking Descriptive Adequacy of 1b model.</a></li>
<li class="chapter" data-level="3.8" data-path="forstmannChapter.html"><a href="forstmannChapter.html#forstMC"><i class="fa fa-check"></i><b>3.8</b> Model Comparison</a><ul>
<li class="chapter" data-level="3.8.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#assessing-descriptive-adequacy-graphically"><i class="fa fa-check"></i><b>3.8.1</b> Assessing Descriptive Adequacy Graphically</a></li>
<li class="chapter" data-level="3.8.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#forstDIC"><i class="fa fa-check"></i><b>3.8.2</b> Model comparison via DIC</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="forstmannChapter.html"><a href="forstmannChapter.html#LBAllcheck"><i class="fa fa-check"></i><b>3.9</b> Checking the LBA log-likelihood function</a><ul>
<li class="chapter" data-level="3.9.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#test-one-do-changes-in-parameter-values-cause-changes-in-the-returned-log-likelihood"><i class="fa fa-check"></i><b>3.9.1</b> Test one: Do changes in parameter values cause changes in the returned log-likelihood?</a></li>
<li class="chapter" data-level="3.9.2" data-path="forstmannChapter.html"><a href="forstmannChapter.html#testing-whether-data-generating-parameter-values-have-the-highest-likelihood"><i class="fa fa-check"></i><b>3.9.2</b> Testing whether data generating parameter values have the highest likelihood</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><i class="fa fa-check"></i><b>4</b> PMwG sampler with the Linear Ballistic Accumulator and a complex experiment design</a><ul>
<li class="chapter" data-level="4.1" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#the-lba-log-likelihood-function-for-the-wagenmakers-data-set"><i class="fa fa-check"></i><b>4.1</b> The LBA log-likelihood function for the Wagenmakers data set</a><ul>
<li class="chapter" data-level="4.1.1" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#what-is-a-log-likelihood-function-1"><i class="fa fa-check"></i><b>4.1.1</b> What is a log-likelihood function?</a></li>
<li class="chapter" data-level="4.1.2" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#writing-the-lba-log-likelihood-for-the-wagenmakers-data-set"><i class="fa fa-check"></i><b>4.1.2</b> Writing the LBA log-likelihood for the Wagenmakers data set</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#wagFastll"><i class="fa fa-check"></i><b>4.2</b> Fast LBA Log-likelihood function</a></li>
<li class="chapter" data-level="4.3" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#pmwg-framework-1"><i class="fa fa-check"></i><b>4.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="4.3.1" data-path="forstmannChapter.html"><a href="forstmannChapter.html#run-sampler"><i class="fa fa-check"></i><b>4.3.1</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#genppdataWag"><i class="fa fa-check"></i><b>4.4</b> Simulating Posterior Predictive Data</a><ul>
<li class="chapter" data-level="4.4.1" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#assessing-descriptive-adequacy-goodness-of-fit-1"><i class="fa fa-check"></i><b>4.4.1</b> Assessing Descriptive Adequacy (goodness of fit)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html"><a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#model-comparison-via-dic"><i class="fa fa-check"></i><b>4.5</b> Model Comparison via DIC</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><i class="fa fa-check"></i><b>5</b> Estimating the Marginal Likelihood via Importance Sampling (IS<sup>2</sup>)</a><ul>
<li class="chapter" data-level="5.1" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#using-is2-with-the-forstmann-dataset"><i class="fa fa-check"></i><b>5.1</b> Using IS2 with the Forstmann dataset</a><ul>
<li class="chapter" data-level="5.1.1" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#load-packages-and-samples"><i class="fa fa-check"></i><b>5.1.1</b> Load packages and samples</a></li>
<li class="chapter" data-level="5.1.2" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#set-up-variables"><i class="fa fa-check"></i><b>5.1.2</b> Set up variables</a></li>
<li class="chapter" data-level="5.1.3" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#store-the-samples"><i class="fa fa-check"></i><b>5.1.3</b> Store the samples</a></li>
<li class="chapter" data-level="5.1.4" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#estimate-the-normal-mix"><i class="fa fa-check"></i><b>5.1.4</b> Estimate the normal mix</a></li>
<li class="chapter" data-level="5.1.5" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#generate-proposal-parameters-from-importance-samples"><i class="fa fa-check"></i><b>5.1.5</b> Generate proposal parameters from importance samples</a></li>
<li class="chapter" data-level="5.1.6" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#write-a-group-distribution-function"><i class="fa fa-check"></i><b>5.1.6</b> Write a group distribution function</a></li>
<li class="chapter" data-level="5.1.7" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#write-a-prior-distribution-function"><i class="fa fa-check"></i><b>5.1.7</b> Write a prior distribution function</a></li>
<li class="chapter" data-level="5.1.8" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#write-a-get_logp-function"><i class="fa fa-check"></i><b>5.1.8</b> Write a get_logp function</a></li>
<li class="chapter" data-level="5.1.9" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#compute-the-lw"><i class="fa fa-check"></i><b>5.1.9</b> Compute the LW</a></li>
<li class="chapter" data-level="5.1.10" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#make-it-work"><i class="fa fa-check"></i><b>5.1.10</b> Make it work</a></li>
<li class="chapter" data-level="5.1.11" data-path="estimating-the-marginal-likelihood-via-importance-sampling-is2.html"><a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html#bootstrapping-for-se"><i class="fa fa-check"></i><b>5.1.11</b> Bootstrapping for SE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="troubleshoot.html"><a href="troubleshoot.html"><i class="fa fa-check"></i><b>6</b> Troubleshooting PMwG errors</a><ul>
<li class="chapter" data-level="6.1" data-path="troubleshoot.html"><a href="troubleshoot.html#writing-your-log-likelihood-function-tips-errors-and-check-list"><i class="fa fa-check"></i><b>6.1</b> Writing your log-likelihood function: Tips, errors and check list</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>7</b> Appendix</a><ul>
<li class="chapter" data-level="7.1" data-path="appendix.html"><a href="appendix.html#wagSDTscript"><i class="fa fa-check"></i><b>7.1</b> Wagenmakers SDT script</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://newcastlecl.org/" target="blank">Published by Newcastle Cognition Lab</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Particle Based Samplers for MCMC</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design" class="section level1 tabset tabset-fade">
<h1><span class="header-section-number">Chapter 4</span> PMwG sampler with the Linear Ballistic Accumulator and a complex experiment design</h1>
<p>In <a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline">chapter 2</a> we demonstrated how the PMwG sampler can be used to model a lexical decision task in a signal detection framework. However, the SDT framework does not allow us to consider response time (RT) and the join distribution of RT and accuracy. In this example we will expand on what was covered in chapter 2, by fitting the LBA - a more complex model - to the Wagenmakers 2008 data.</p>
<p>A description of the Wagenmakers experiment and data is covered in <a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline">chapter 2</a>. This experiment is more complicated than the Forstmann example in <a href="forstmannChapter.html#forstmannChapter">chapter 3</a>, and the LBA is also more complicated than the SDT model. As a result, the log-likelihood function for this example will be more complex, however, you’ll notice that each step closely follows those taken in previous chapters with simpler data sets and simpler models.</p>
<div id="the-lba-log-likelihood-function-for-the-wagenmakers-data-set" class="section level2">
<h2><span class="header-section-number">4.1</span> The LBA log-likelihood function for the Wagenmakers data set</h2>
<div id="what-is-a-log-likelihood-function-1" class="section level3">
<h3><span class="header-section-number">4.1.1</span> What is a log-likelihood function?</h3>
<p>If you’re unsure what a log-likehood function is and/or does, see our explanation <a href="pmwg-sampler-and-signal-detection-theory.html#WTFisaLLf">here</a>.</p>
</div>
<div id="writing-the-lba-log-likelihood-for-the-wagenmakers-data-set" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Writing the LBA log-likelihood for the Wagenmakers data set</h3>
<p>As we have shown in the previous two examples, we include a computationally-slow and easy to follow log-likelihood function. The log-likelihood function steps through the data line by line (i.e. trial by trial) and gives a likelihood value for each line given <code>x</code> parameters. As mentioned in previous chapters, we encourage those who have experience writing likelihood functions to write a computationally efficient function or use our <a href="pmwg-sampler-with-the-linear-ballistic-accumulator-and-a-complex-experiment-design.html#wagFastll">fast LBA log-likelihood function</a>. For those new to modelling, the trialwise function directly below is easier to follow, debug and is less likely to result in errors. The down side is that the slow/trialwise log-likelihood function is approximately five times slower to run than the fast log-likelihood function.</p>
<p>The structure of our log-likelihood function follows those in the preceding chapters, so we will focus on the parts that differ i.e. the experiment design and hypothesis about which parameters are being influenced by the experimental manipulations. See <a href="forstmannChapter.html#LBAParameters">chapter 3</a> for an outline of the LBA parameters.</p>
<p>Let’s begin by loading <code>rtdists</code> package…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rtdists)</code></pre></div>
<p>…and now a complete trialwise (slow) log-likelihood function.</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">tw_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  
  <span class="cf">if</span> (sample) {
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b.w =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>cond[i], <span class="st">&quot;.W&quot;</span>)] <span class="op">+</span><span class="st"> </span>A
    b.nw =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>cond[i], <span class="st">&quot;.NW&quot;</span>)] <span class="op">+</span><span class="st"> </span>A
    bs =<span class="st"> </span><span class="kw">list</span>(b.nw, b.w)
    v.w =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;v.&quot;</span>, data<span class="op">$</span>stim[i], <span class="st">&quot;.W&quot;</span>)]
    v.nw =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;v.&quot;</span>, data<span class="op">$</span>stim[i], <span class="st">&quot;.NW&quot;</span>)]
    vs =<span class="st"> </span><span class="kw">c</span>(v.nw, v.w)
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    
    <span class="cf">if</span> (sample) {
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> bs,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
      )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    } <span class="cf">else</span> {
      out[i] &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt[i],
                     <span class="dt">response =</span> data<span class="op">$</span>resp[i],
                     <span class="dt">A =</span> A,
                     <span class="dt">b =</span> bs,
                     <span class="dt">mean_v =</span> vs,
                     <span class="dt">sd_v =</span> s,
                     <span class="dt">t0 =</span> t0,
                     <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                     <span class="dt">silent =</span> <span class="ot">TRUE</span>
                     )
      }
  }
  <span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }
}</code></pre></td></tr></table></div>
<p><b>Note:</b> If you’d like to run through this example, it is best to copy the <code>tw_lba_ll</code> function from the code block above rather than copying from the separate code chunks below where curly braces have been removed.</p>
<p>We begin from the <code>for</code> loop on line 14. For for each row in the dataset, we assign the values (<code>x</code>) of each parameter in our model so that any conditional parameters (for example <code>b</code> in our model) are correctly assigned. For the Wagenmakers data set, we want to calculate the density function for a model that has a threshold (<code>b</code>) parameter for each of the conditions (<code>cond</code> = <code>w</code>: 75% words &amp; 25% non-words, <code>nw</code>: 75% non-words &amp; 25% words). We also want threshold to vary for respone (<code>resp</code>) type (i.e., the accumulator for a word (<code>W</code>) response, and the accumulator for the non-word (<code>NW</code>). So, on lines 16 and 17, we paste together the <code>&quot;b.&quot;</code> threshold parameter, the condition (<code>cond</code> = <code>w</code> or <code>nw</code>) and the response <code>&quot;.W&quot;</code> or <code>&quot;.NW&quot;</code> and add the start point parameter <code>A</code>. The start point parameter is added to the threshold values to ensure that threshold is greater than the start point value.</p>
<p>We hypothesised that drift rate <code>v</code> would vary with word frequency (<code>stim</code> = <code>hf</code>,<code>lf</code>,<code>vlf</code>,<code>nw</code>), so on lines 19 and 20 we allow drift rate for response <i>word</i> (<code>v.w</code>) to vary with the levels of word frequency, by pasting the <code>&quot;v.&quot;</code> with <code>stim</code> and with the accumulator for each response (<code>&quot;.W&quot;</code> or <code>&quot;.NW&quot;</code>). You’ll notice that in this example, we no longer have a drift rate for the correct response (<code>vc</code>) or incorrect response (<code>ve</code>), instead, we have a drift rate for responding <i>word</i> (<code>v.w</code>) and <i>non-word</i> (<code>v.nw</code>). This is a different way (and our preferred way) of coding drift rate. On line 21 we have ordered the <code>vs</code> vector with <code>v.nw</code> first and <code>v.w</code> second.</p>
<div class="sourceCode" startFrom="14"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>14
15
16
17
18
19
20
21
22
23
</pre></td><td class="sourceCode"><pre><code class="sourceCode r"> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b.w =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>cond[i], <span class="st">&quot;.W&quot;</span>)] <span class="op">+</span><span class="st"> </span>A
    b.nw =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>cond[i], <span class="st">&quot;.NW&quot;</span>)] <span class="op">+</span><span class="st"> </span>A
    bs =<span class="st"> </span><span class="kw">list</span>(b.nw, b.w)
    v.w =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;v.&quot;</span>, data<span class="op">$</span>stim[i], <span class="st">&quot;.W&quot;</span>)]
    v.nw =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;v.&quot;</span>, data<span class="op">$</span>stim[i], <span class="st">&quot;.NW&quot;</span>)]
    vs =<span class="st"> </span><span class="kw">c</span>(v.nw, v.w)
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)</code></pre></td></tr></table></div>
<p>It is important to check the order of your levels for the response factor to ensure you correctly order your <code>v.nw</code> and <code>v.w</code> accumulators in the <code>vs</code> vector.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">levels</span>(data<span class="op">$</span>resp)</code></pre></div>
<pre><code>## [1] &quot;1&quot; &quot;2&quot;</code></pre>
<p>If we look at our levels for response, we see the order is <code>NW</code> and <code>W</code> respectively. This means that <code>NW</code> is coded as <code>1</code> and <code>W</code> is coded as <code>2</code>. Therefore, on line 36, if <code>data$resp[i] = N.W</code> then the level is 1, and the first accumulator in position 1 will be chosen. If <code>data$resp[i] = W</code> this tells the sampler that the accumulator in position 2 will be chosen. In other words, the parameters will map correctly because <code>v.nw</code> is in position 1 and <code>v.w</code> in position 2 in our <code>vs</code> vector.</p>
<p>The remaining lines of the log-likelihood function are identical to the function used in the Forstmann example in <a href="forstmannChapter.html#forstmannChapter">chapter 3</a>, except the threshold parameter <code>bs</code> (line 29 and 44) is a list with two elements (<code>b = bs</code>)</p>
</div>
</div>
<div id="wagFastll" class="section level2">
<h2><span class="header-section-number">4.2</span> Fast LBA Log-likelihood function</h2>
<p>As we mentioned in section <a href="forstmannChapter.html#fstLBALL">3.3.3</a>, the data is large and the dLBA function takes some time to run, so the log-likelihood code above is computationally inefficient. There are several ways to improve the log-likelihood’s performance; in our example below, we reduce the number of calls to dLBA to one call. We do this by passing a list of dLBA parameter values for the length of the data.</p>
<p>Note: When generating posterior predictive data, the rLBA function is still executed for each row of data; however, it is only executed several times, so computational efficiency is uncompromised.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fast_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  b.w =<span class="st"> </span>b.nw =<span class="st"> </span>v.w =<span class="st"> </span>v.nw =<span class="st"> </span>out =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    <span class="cf">for</span> (p <span class="cf">in</span> <span class="kw">unique</span>(data<span class="op">$</span>prop)) {
      use &lt;-<span class="st"> </span>data<span class="op">$</span>cond <span class="op">==</span><span class="st"> </span>p  
      b.w[use] =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, p, <span class="st">&quot;.W&quot;</span>)] <span class="op">+</span><span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
      b.nw[use] =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, p, <span class="st">&quot;.NW&quot;</span>)] <span class="op">+</span><span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    }
    <span class="cf">for</span> (f <span class="cf">in</span> <span class="kw">unique</span>(data<span class="op">$</span>freq)) {
      use &lt;-<span class="st"> </span>data<span class="op">$</span>stim <span class="op">==</span><span class="st"> </span>f 
      v.w[use] =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;v.&quot;</span>, f, <span class="st">&quot;.W&quot;</span>)]
      v.nw[use] =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;v.&quot;</span>, f, <span class="st">&quot;.NW&quot;</span>)]
        }
    bs =<span class="st"> </span><span class="kw">list</span>(b.nw,b.w)
    vs =<span class="st"> </span><span class="kw">list</span>(v.nw,v.w)
    
  <span class="cf">if</span> (<span class="op">!</span>sample){
    out &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt,
                <span class="dt">resp =</span> data<span class="op">$</span>resp,
                <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                <span class="dt">b =</span> bs,
                <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                <span class="dt">mean_v =</span> vs,
                <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), 
                <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                <span class="dt">silent =</span> <span class="ot">TRUE</span>)
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">pmax</span>(out,<span class="fl">1e-10</span>)))
    <span class="kw">return</span>(out)
  } <span class="cf">else</span> {
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="ot">NA</span>
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="ot">NA</span>
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)){
      tmp&lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                 <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                 <span class="dt">b =</span> <span class="kw">list</span>(b.nw[i], b.w[i]),
                 <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                 <span class="dt">mean_v =</span> <span class="kw">list</span>(v.nw[i], v.w[i]),
                 <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                 <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                 <span class="dt">silent =</span> <span class="ot">TRUE</span>)
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    }
      <span class="kw">return</span>(data)
  }
}</code></pre></div>
<p>You should improve your log-likelihood’s performance as you see fit. When you’re confident that your log-likelihood code functions correctly, we suggest saving it as a separate script so it can be sourced and loaded when running the sampler. If you’re learning how to write log-likelihood functions, take a look at our <a href="troubleshoot.html#troubleshoot">troubleshooting section</a> for tips. In our experience, a very large proportion of problems with sampling and inference are caused by inadequate checking and care in the likelihood function.</p>
</div>
<div id="pmwg-framework-1" class="section level2">
<h2><span class="header-section-number">4.3</span> PMwG Framework</h2>
<p>Now that we have a log-likelihood function, we can set up the <code>PMwG</code> sampler. To run the sampler, we simply follow the procedure from <a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline">chapter 2</a> and <a href="forstmannChapter.html#forstmannChapter">chapter 3</a>; we need to set up a vector of model parameter names, create a <code>priors</code> object, source our LBA log-likelihood script and then create our <code>sampler</code> object.</p>
<p>First, load the <code>PMwG</code> library and data…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pmwg)
<span class="kw">load</span>(<span class="st">&quot;dataObjects/wagenmakers2008.RData&quot;</span>)</code></pre></div>
<p>Let’s create a vector of model parameter names. Remember that this must match the names and number of parameters you include in your log-likelihood function. You can name this vector as you wish; however, in our example, we name it <code>pars</code>.</p>
<p>For the Wagenmakers dataset, we require four threshold parameters because we assume that both word proportion (<code>cond</code>) and response (<code>resp</code>) have an effect on level of caution (i.e. a threshold parameter for each combination of word proportion and response). We also need a <i> drift rate</i> for each cell of our design i.e. eight drift rate parameters; one for each level of <code>word frequency</code> (<code>hf</code>,<code>lf</code>,<code>vlf</code>,<code>nw</code>) for the Word response accumulator <code>.W</code>, and the non-word response accumulator <code>.NW</code>).</p>
<p>We’ve made a decision to set the <code>sv</code> to 1 to satisfy the scaling properties of the model. As such, we haven’t included the <code>sv</code> parameter in the <code>pars</code> vector - it is found in the LBA’s log-likelihood function (see below).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>,
         <span class="st">&quot;b.nw.NW&quot;</span>,
         <span class="st">&quot;b.nw.W&quot;</span>,
         <span class="st">&quot;b.w.NW&quot;</span>,
         <span class="st">&quot;b.w.W&quot;</span>,
         <span class="st">&quot;v.hf.NW&quot;</span>,
         <span class="st">&quot;v.hf.W&quot;</span>,
         <span class="st">&quot;v.lf.NW&quot;</span>,
         <span class="st">&quot;v.lf.W&quot;</span>,
         <span class="st">&quot;v.vlf.NW&quot;</span>,
         <span class="st">&quot;v.vlf.W&quot;</span>,
         <span class="st">&quot;v.nw.NW&quot;</span>,
         <span class="st">&quot;v.nw.W&quot;</span>,
         <span class="st">&quot;t0&quot;</span>)</code></pre></div>
<p>For the mean of the distribution for random effects (theta_mu), we assume a multivariate normal prior. The user can specify the mean and variance of this prior distribution using the object <code>priors</code>, which has elements <code>theta_mu_mean</code> and <code>theta_mu_var</code>. A typical setting for LBA models is to set <code>theta_mu_mean</code> to be a zero vector and to set <code>theta_mu_var</code> to be a multiple of the identity matrix, e.g. with 9 on the diagonal (representing a standard deviation of 3 for the subject-level means in the prior).</p>
<p>We create our <code>priors</code> object; a list that contains two components:</p>
<ul>
<li><code>theta_mu_mean</code> a vector containing the prior for model parameter means</li>
<li><code>theta_mu_var</code> the prior covariance matrix for model parameters.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">priors &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">theta_mu_mean =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(pars)),
  <span class="dt">theta_mu_var =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(pars)))
)</code></pre></div>
<p>Now source and load your log-likelihood script <i>before</i> you create the sampler object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="dt">file =</span> <span class="st">&quot;fast_lba_ll.R&quot;</span>)</code></pre></div>
<p>Next we specify the PMwG <code>sampler</code> object. The <code>pmwgs</code> function takes a set of arguments (listed below) and returns a list containing the required components for performing the particle metropolis within Gibbs steps.</p>
<ul>
<li><code>data =</code> your data - a data frame (e.g.<code>wagenmakers</code>) with a column for participants called <b><code>subject</code></b></li>
<li><code>pars =</code> the model parameters to be used (e.g.<code>pars</code>)</li>
<li><code>prior =</code> the priors to be used (e.g.<code>priors</code>)</li>
<li><code>ll_func =</code> name of log-likelihood function to be used (e.g.<code>fast_lba_ll</code>)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">pmwgs</span>(<span class="dt">data =</span> data,
                 <span class="dt">pars =</span> pars,
                 <span class="dt">prior =</span> priors,
                 <span class="dt">ll_func =</span> fast_lba_ll
                 )</code></pre></div>
<div id="run-sampler" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Running the sampler</h3>
<p>Setup is now complete and we can run the sampler. First, we use the <code>init</code> function to generate initial start points for the random effects and store them in the <code>sampler</code> object. If you wanted you could include start points for your chain. We will not specify start points as we did in the Forstmann three threshold model. This is why have not included a <code>start_mu</code> and a <code>start_sig</code>. Instead, the start points will be drawn from the prior. <b>Note:</b> The <code>init</code> stage can take some time to run because it uses a large number of particles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">init</span>(sampler)</code></pre></div>
<p><br> To run the sampler, we use the <code>run_stage</code> function. To execute the <code>run_stage</code> function, you <b>must</b> provide values for two arguments:</p>
<ul>
<li><code>pmwgs =</code> the <code>sampler</code> object including parameters that were created by the <code>init</code> function above.</li>
<li><code>stage =</code> the sampling stage (In order; <code>&quot;burn&quot;</code>, <code>&quot;adapt&quot;</code> or <code>&quot;sample&quot;</code>).</li>
</ul>
<p>The following arguments listed below are optional:</p>
<ul>
<li><code>iter =</code> is the number of iterations for the sampling stage. For burn-in, it is important to have enough iterations that the chains converge on the posterior distribution. Default = 1000.</li>
<li><code>particles =</code> is the number of proposals (particles) generated for each random effect, on each iteration. Default = 1000, but set smaller or larger in order to target a reasonable acceptance rate (i.e. 10-60%).</li>
<li><code>display_progress =</code> display a progress bar during sampling</li>
<li><code>epsilon =</code> is a value greater than 0 which scales the variance of the proposal distribution. Smaller values (i.e. narrower proposal distributions) can lead to higher acceptance rates, but slower coverage of the posterior. Smaller values are especially useful when the number of random effects is large (e.g. &gt;10). The default is adaptively chosen based on the number of parameters.</li>
<li><code>n_cores =</code> the number of cores on a machine you wish to use to run the sampler. This allows sampling to be run across cores (parallelising for subjects). Default = 1. <b> Note:</b> Setting <code>n_cores</code> greater than 1 is only permitted on Linux and Mac OS X machines.</li>
</ul>
<p>The first sampling stage is burn-in <code>&quot;burn&quot;</code>. The burn-in stage allows time for the sampler to move from the (arbitrary) start points that were provided by the user to the mode of the posterior distribution. This can be checked by examining the chains for stationarity. We take the <code>sampler</code> object created in the <code>init</code> function above, set the stage argument to <code>&quot;burn&quot;</code> and assign the outcome to an object called <code>burned</code>. Iterations for burn-in (in this example <code>iter = 1000</code>) are set by choosing a sufficient number of iterations that will get the sampler to the posterior space <b>Note:</b> You should visually check the chains for convergence/stationarity after burn-in.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">burned &lt;-<span class="st"> </span><span class="kw">run_stage</span>(sampler, 
                    <span class="dt">stage =</span> <span class="st">&quot;burn&quot;</span>,
                    <span class="dt">iter =</span> <span class="dv">1000</span>,
                    <span class="dt">particles =</span> <span class="dv">100</span>
                    )</code></pre></div>
<p>Next is the adaptation stage <code>&quot;adapt&quot;</code>. The adaptation stage draws samples using a simple, but relatively inefficient proposal distribution (the same proposal distribution as the <code>&quot;burn&quot;</code>stage). Enough samples are drawn to allow the algorithm to estimate a much more sophisticated and efficient proposal distribution, using conditional normal distributions. We take the <code>burned</code> object created in the previous stage and set iterations <code>iter =</code> to a high number (e.g. <code>10000</code>), as it should exit before reaching this point. If it doesn’t, there is likely an issue with acceptance rates, the likelihood function or limited data to operate on (i.e. few trials in some conditions). Here, we have saved the outcome of the adaptation stage to an object called <code>adapted</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adapted &lt;-<span class="st"> </span><span class="kw">run_stage</span>(burned, 
                     <span class="dt">stage =</span> <span class="st">&quot;adapt&quot;</span>, 
                     <span class="dt">iter =</span> <span class="dv">5000</span>, 
                     <span class="dt">particles =</span> <span class="dv">100</span>
                     )</code></pre></div>
<p>The final stage is the sampling stage <code>&quot;sample&quot;</code>. The sampling stage uses the sophisticated and adaptive conditional normal proposal distributions. This allows for very efficient sampling, using far fewer particles. Samples from this stage are taken from the ‘posterior distribution’ and stored in the <code>sampled</code> object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampled &lt;-<span class="st"> </span><span class="kw">run_stage</span>(adapted, 
                     <span class="dt">stage =</span> <span class="st">&quot;sample&quot;</span>,
                     <span class="dt">iter =</span> <span class="dv">10000</span>, 
                     <span class="dt">particles =</span> <span class="dv">100</span>
                     )</code></pre></div>
<p>The <code>sampled</code> object includes all samples from the <code>&quot;sample&quot;</code> stage above and the following elements:</p>
<ul>
<li><code>data</code> : the data (data frame) you included in your analysis</li>
<li><code>par_names</code>: parameter names</li>
<li><code>n_pars</code>: number of parameters</li>
<li><code>n_subjects</code>: number of subjects</li>
<li><code>subjects</code>: subject IDs (1:n)</li>
<li><code>prior</code>: list of the prior used</li>
<li><code>ll_func</code>: the likelihood function specified</li>
<li><code>samples</code>:</li>
<li><code>alpha</code>: three dimensional array of random effects draws (dim = parameters x subjects x samples)</li>
<li><code>theta_mu</code>: two dimensional array of parameter draws (dim = parameters x samples)</li>
<li><code>theta_sig</code>: three dimensional array of covariance matrix draws (dim = covariance x samples)</li>
<li><code>stage</code>: specifies the stage the sample is from (length = samples)</li>
<li><code>subj_ll</code>: likelihood value for each subject for each iteration (dim = subject x samples)</li>
<li><code>a_half</code>: the parameter used in calculating the inverse Wishart (dim = parameters x samples)</li>
<li><code>idx</code>: total number of samples</li>
<li><code>last_theta_sig_inv</code>: the inverse of the last sample for theta_sig (the variance-covariance matrix).</li>
</ul>
<p>You should save your sampled object at this point.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">save</span>(sampled, <span class="dt">file =</span> <span class="st">&quot;wagSamp.RData&quot;</span>)</code></pre></div>
<p>For help with determining an appropriate number of iterations and particles required for your model estimation, see <a href="forstmannChapter.html#estSet">estimation settings for the PMwG sampler</a> in chapter 3.</p>
</div>
</div>
<div id="genppdataWag" class="section level2">
<h2><span class="header-section-number">4.4</span> Simulating Posterior Predictive Data</h2>
<p>We can generate posterior predictive data by setting <code>sample = TRUE</code> in our log-likelihood function to generate response times and responses <i>given</i> the posterior parameter estimates for each subject. To do this, we use the <code>gen_pp_data</code> function below, which calls the log-likelihood function embedded in our <code>sampled</code> object. The <code>gen_pp_data</code> function takes four arguments:</p>
<ul>
<li><code>sampled</code>: is the object/output from the PMwG sampler</li>
<li><code>n</code>: the number of posterior samples</li>
<li><code>ll_func =</code>: the log-likelihood function embedded in the <code>sampled</code> object</li>
<li><code>rbind.data =</code>: bind the rows of each predictive sample into a rectangular array, or leave as a list.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gen_pp_data &lt;-<span class="st"> </span><span class="cf">function</span> (sampled, n, <span class="dt">ll_func =</span> sampled<span class="op">$</span>ll_func, <span class="dt">rbind.data =</span> <span class="ot">TRUE</span>) {
  sampled_stage &lt;-<span class="st"> </span><span class="kw">length</span>(sampled<span class="op">$</span>samples<span class="op">$</span>stage[sampled<span class="op">$</span>samples<span class="op">$</span>stage <span class="op">==</span><span class="st"> &quot;sample&quot;</span>])
  iterations &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dt">from =</span> (sampled<span class="op">$</span>samples<span class="op">$</span>idx <span class="op">-</span><span class="st"> </span>sampled_stage),
                            <span class="dt">to =</span> sampled<span class="op">$</span>samples<span class="op">$</span>idx,
                            <span class="dt">length.out =</span> n))
  data &lt;-<span class="st"> </span>sampled<span class="op">$</span>data
  S &lt;-<span class="st"> </span>sampled<span class="op">$</span>n_subjects
  pp_data &lt;-<span class="st"> </span><span class="kw">list</span>()
  
    <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>S){
       <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;subject&quot;</span>, s))
      <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(iterations)) {
        <span class="kw">print</span>(i)
        x &lt;-<span class="st"> </span>sampled<span class="op">$</span>samples<span class="op">$</span>alpha[, s, iterations[i]]
        <span class="kw">names</span>(x) &lt;-<span class="st"> </span>sampled<span class="op">$</span>data
        out &lt;-<span class="st"> </span><span class="kw">ll_func</span>(<span class="dt">x =</span> x, 
                       <span class="dt">data =</span> data[data<span class="op">$</span>subject <span class="op">==</span><span class="st"> </span><span class="kw">unique</span>(data<span class="op">$</span>subject)[s], ],
                       <span class="dt">sample =</span> <span class="ot">TRUE</span>)
        
        <span class="cf">if</span> (i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>){
          pp_data[[s]] =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">pp_iter =</span> i, out)
        }
        <span class="cf">else</span> {
          pp_data[[s]] =<span class="st"> </span><span class="kw">rbind</span>(pp_data[[s]],
                         <span class="kw">cbind</span>(<span class="dt">pp_iter =</span> i, out))
        }
      }
    }
  
    <span class="cf">if</span> (rbind.data){
    tidy_pp_data &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, pp_data)  
    <span class="kw">return</span>(tidy_pp_data)
    }
    <span class="cf">else</span> {
      <span class="kw">return</span>(pp_data)
    }
}</code></pre></div>
<p>We generate 20 posterior predictive data samples.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ppdataWag &lt;-<span class="st"> </span><span class="kw">gen_pp_data</span>(sampled, <span class="dt">n =</span> <span class="dv">20</span>)</code></pre></div>
<p>The returned data is a matrix with the same dimensions and names as <code>wagenmakers</code> – with the addition of <code>pp_iter</code> column. <code>pp_iter</code> is the iteration of the posterior sample (in this example <code>i = 1:20</code>) for the corresponding subject. We now have two matrices based on samples from either model. The response (<code>resp</code>) and response time (<code>rt</code>) columns now contain posterior predictive data.</p>
<p>In the next section, we will use the posterior predictive data to assess descriptive adequacy.</p>
<div id="assessing-descriptive-adequacy-goodness-of-fit-1" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Assessing Descriptive Adequacy (goodness of fit)</h3>
<p>Now we will plot the posterior predictive data against the real data. In the section below we compare observed RTs against predicted RTs, which is common for RT modelling; however, the code could also be modified for different types of data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Recode condition column in order to calculate accuracy</span>
<span class="co"># Data</span>
wagenmakers<span class="op">$</span>condition &lt;-<span class="st"> </span><span class="kw">recode</span>(wagenmakers<span class="op">$</span>condition, <span class="dt">w =</span> <span class="st">&quot;W&quot;</span>, <span class="dt">nw =</span><span class="st">&quot;NW&quot;</span> )
wagenmakers<span class="op">$</span>correct &lt;-<span class="st"> </span>wagenmakers<span class="op">$</span>correct <span class="op">-</span><span class="st"> </span><span class="dv">1</span>
<span class="co"># Posterior predictive data</span>
ppdataWag<span class="op">$</span>condition &lt;-<span class="st"> </span><span class="kw">recode</span>(ppdataWag<span class="op">$</span>condition, <span class="dt">w =</span> <span class="st">&quot;W&quot;</span>, <span class="dt">nw =</span><span class="st">&quot;NW&quot;</span> )
ppdataWag<span class="op">$</span>binary_stim &lt;-<span class="st"> </span><span class="kw">ifelse</span>(ppdataWag<span class="op">$</span>stim <span class="op">==</span><span class="st">&quot;nw&quot;</span>, <span class="dv">1</span>, <span class="dv">2</span>)
ppdataWag<span class="op">$</span>correct &lt;-<span class="st"> </span><span class="kw">ifelse</span>(ppdataWag<span class="op">$</span>binary_stim <span class="op">==</span><span class="st"> </span>ppdataWag<span class="op">$</span>response, <span class="dv">1</span>, <span class="dv">0</span>)

<span class="co"># Subject x condition Q25, median and Q75 respone time + mean accuracy </span>
<span class="co"># Wagenmakers dataset</span>
pqWag &lt;-<span class="st"> </span>wagenmakers <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(subject, condition, stim) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt), 
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span>  <span class="kw">mean</span>(correct),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Subject x condition Q25, median and Q75 respone time for posterior predictive data</span>
pp_pqWag &lt;-<span class="st"> </span>ppdataWag <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, subject, stim) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Q25 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.25</span>),
            <span class="dt">median =</span> <span class="kw">median</span>(rt), 
            <span class="dt">Q75 =</span> <span class="kw">quantile</span>(rt, <span class="dt">prob =</span> <span class="fl">0.75</span>),
            <span class="dt">acc =</span> <span class="kw">mean</span>(correct),
            <span class="dt">.groups =</span> <span class="st">&quot;keep&quot;</span>
            )

<span class="co"># Combine data with posterior predictive data and add data source</span>
pqWag &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(<span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;data&quot;</span>, <span class="kw">nrow</span>(pqWag)), pqWag),
                <span class="kw">cbind</span>(<span class="dt">src =</span> <span class="kw">rep</span>(<span class="st">&quot;model&quot;</span>, <span class="kw">nrow</span>(pp_pqWag)), pp_pqWag)
                )

<span class="co"># Mean Q25, median, Q4 and accuracy for data and posterior predictive data</span>
av_pqWag &lt;-<span class="st"> </span>pqWag <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(src, condition, stim) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Variances of posterior samples</span>
pp_varWag &lt;-<span class="st"> </span>pqWag <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(src <span class="op">!=</span><span class="st"> &quot;data&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition, pp_iter, src, stim) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Q25<span class="op">:</span>acc), mean)

<span class="co"># Convert source column to a factor and add labels</span>
av_pqWag<span class="op">$</span>src &lt;-<span class="st"> </span><span class="kw">factor</span>(av_pqWag<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>)
                    )

pp_varsrcWag &lt;-<span class="st"> </span><span class="kw">factor</span>(pp_varWag<span class="op">$</span>src,
                    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>),
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;data&quot;</span>)
                    )
<span class="co"># Rename conditions</span>
<span class="kw">levels</span>(av_pqWag<span class="op">$</span>condition) &lt;-
<span class="st">  </span><span class="kw">levels</span>(pp_varWag<span class="op">$</span>condition) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;75% </span><span class="ch">\n</span><span class="st">Non-Word </span><span class="ch">\n</span><span class="st">stimuli&quot;</span>,<span class="st">&quot;75% </span><span class="ch">\n</span><span class="st">Word stimuli&quot;</span>)
<span class="co"># Change plot stimuli labels</span>



<span class="co"># Convert rt to milliseconds and acc to percentage</span>
av_pqWag<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>av_pqWag<span class="op">$</span>acc
pp_varWag<span class="op">$</span>acc &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>pp_varWag<span class="op">$</span>acc
av_pqWag[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>av_pqWag[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]
pp_varWag[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="op">*</span><span class="st"> </span>pp_varWag[, <span class="kw">c</span>(<span class="st">&quot;Q25&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;Q75&quot;</span>)]</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/ppdataplotarrgWag-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="model-comparison-via-dic" class="section level2">
<h2><span class="header-section-number">4.5</span> Model Comparison via DIC</h2>
<p>Deviance information criterion (DIC) can be used as a metric to compare two models, and assess which model fits the data best, with penalties applied to model complexity. <b>Note:</b> we recommend using marginal likelihood (Bayes factors) instead of DIC for model selection. For more information, see this paper on <a href="https://link.springer.com/article/10.3758/s13428-020-01348-w">estimating the Marginal Likelihood via importance sampling</a>.</p>
<p>In this chapter we have covered one LBA model, however; we have included a DIC function and DIC value for completeness. To see an example where DIC is used as a model selection technique, see <a href="forstmannChapter.html#forstDIC">chapter 3</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pmwg_DIC &lt;-<span class="st"> </span><span class="cf">function</span>(sampled, <span class="dt">pD =</span> <span class="ot">FALSE</span>){
  <span class="co"># Identify number of subjects</span>
  nsubj &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(sampled<span class="op">$</span>data<span class="op">$</span>subject))
 
  <span class="co"># Mean log-likelihood of the overall (sampled-stage) model, for each subject</span>
  mean_ll &lt;-<span class="st"> </span><span class="kw">apply</span>(sampled<span class="op">$</span>samples<span class="op">$</span>subj_ll[, sampled<span class="op">$</span>samples<span class="op">$</span>stage <span class="op">==</span><span class="st"> &quot;sample&quot;</span>],
                   <span class="dv">1</span>,
                   mean)
 
  <span class="co"># Mean of each parameter across iterations.</span>
  <span class="co"># Keep dimensions for parameters and subjects</span>
  mean_pars &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(sampled<span class="op">$</span>samples<span class="op">$</span>alpha[,, sampled<span class="op">$</span>samples<span class="op">$</span>stage <span class="op">==</span><span class="st"> &quot;sample&quot;</span>],
                       <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,
                       mean))

 
  <span class="co"># Name &#39;mean_pars&#39; so it can be used by the log_like function</span>
  <span class="kw">colnames</span>(mean_pars) &lt;-<span class="st"> </span>sampled<span class="op">$</span>par_names
 
  <span class="co"># log-likelihood for each subject using their mean parameter vector</span>
  mean_pars_ll &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">ncol</span>(mean_pars))
  
  data &lt;-<span class="st"> </span><span class="kw">transform</span>(sampled<span class="op">$</span>data, 
                    <span class="dt">subject =</span> <span class="kw">match</span>(subject, <span class="kw">unique</span>(subject)))
  
  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsubj) {
    mean_pars_ll[j] &lt;-<span class="st"> </span>sampled<span class="op">$</span><span class="kw">ll_func</span>(mean_pars[j, ],
                                       <span class="dt">data =</span> data[data<span class="op">$</span>subject <span class="op">==</span><span class="st"> </span>j,],
                                       <span class="dt">sample =</span> <span class="ot">FALSE</span>)
  }
 
  <span class="co"># Effective number of parameters</span>
  pD &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>mean_ll <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>mean_pars_ll)
 
  <span class="co"># Deviance Information Criterion</span>
  DIC &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>mean_ll <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>mean_pars_ll)
 
  <span class="cf">if</span> (pD){
    <span class="kw">return</span>(<span class="kw">c</span>(<span class="st">&quot;DIC &quot;</span> =<span class="st"> </span>DIC, <span class="st">&quot; Effective parameters&quot;</span> =<span class="st"> </span>pD))
  }<span class="cf">else</span>{
    <span class="kw">return</span>(DIC)
  }
   
}</code></pre></div>
<p>We calculate a DIC value for a model by passing the <code>sampled</code> object into the <code>pmwgDIC</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load Wagenmakers sampled object and assign to variable &quot;sampledWag&quot;</span>
<span class="kw">load</span>(<span class="st">&quot;wagLBAsamp.RData&quot;</span>)
sampledWag &lt;-<span class="st"> </span>sampled
<span class="kw">pmwg_DIC</span>(<span class="dt">sampled =</span> sampledWag)</code></pre></div>
<pre><code>             DIC   Effective parameters 
      -20085.6336              224.2085 </code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="forstmannChapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimating-the-marginal-likelihood-via-importance-sampling-is2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-wagLBA.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
